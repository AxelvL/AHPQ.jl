{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-08T18:36:13.306000+01:00",
     "start_time": "2021-02-08T17:35:51.338Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "include(\"../src/AHPQ.jl\")\n",
    "using .AHPQ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Artificial Data Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-08T18:36:28.138000+01:00",
     "start_time": "2021-02-08T17:35:51.917Z"
    }
   },
   "outputs": [],
   "source": [
    "using Plots\n",
    "using Statistics: norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-08T18:36:44.910000+01:00",
     "start_time": "2021-02-08T17:35:52.221Z"
    }
   },
   "outputs": [],
   "source": [
    "n_dp = 1000\n",
    "n_dim = 16\n",
    "n_queries = 100\n",
    "n_neighbors = 100\n",
    "\n",
    "data = rand(n_dim, n_dp)\n",
    "data = data ./ mapslices(norm, data, dims=1)\n",
    "queries = rand(n_dim, n_queries)\n",
    "innerproducts = data' * queries\n",
    "groundtruth = mapslices(x -> partialsortperm(x, 1:n_neighbors, rev=true), innerproducts,dims=1);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 16x1.000 Dataset and 8x8 codebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-08T18:36:44.911000+01:00",
     "start_time": "2021-02-08T17:35:52.956Z"
    }
   },
   "outputs": [],
   "source": [
    "n_codebooks = 8\n",
    "n_centers   = 8\n",
    "recalln = 20\n",
    "stopcond= 2e-1;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding optimal `T`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-08T18:39:40.121000+01:00",
     "start_time": "2021-02-08T17:39:37.243Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1244345532349254\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Starting incremental initialisation...\n",
      "└ @ Main.AHPQ C:\\Users\\Axel9\\.julia\\dev\\AHPQ\\src\\builder.jl:73\n",
      "┌ Info: \n",
      "│ \n",
      "│ Fitting quantizer on 20 data points...\n",
      "└ @ Main.AHPQ C:\\Users\\Axel9\\.julia\\dev\\AHPQ\\src\\quantizer\\quantizer.jl:74\n",
      "┌ Info: Starting L2 Quantization...\n",
      "└ @ Main.AHPQ C:\\Users\\Axel9\\.julia\\dev\\AHPQ\\src\\quantizer\\quantizer.jl:14\n",
      "┌ Info: Iteration loss: 0.36275709366724956\tUpdate distance:0.3048805903993764\n",
      "└ @ Main.AHPQ C:\\Users\\Axel9\\.julia\\dev\\AHPQ\\src\\quantizer\\quantizer.jl:27\n",
      "┌ Info: Iteration loss: 0.31222164991501966\tUpdate distance:0.14394341169531813\n",
      "└ @ Main.AHPQ C:\\Users\\Axel9\\.julia\\dev\\AHPQ\\src\\quantizer\\quantizer.jl:27\n",
      "┌ Info: Product quantization converged after 2 iterations\n",
      "└ @ Main.AHPQ C:\\Users\\Axel9\\.julia\\dev\\AHPQ\\src\\quantizer\\quantizer.jl:30\n",
      "┌ Info: \n",
      "│ \n",
      "│ Fitting quantizer on 200 data points...\n",
      "└ @ Main.AHPQ C:\\Users\\Axel9\\.julia\\dev\\AHPQ\\src\\quantizer\\quantizer.jl:79\n",
      "┌ Info: Starting L2 Quantization...\n",
      "└ @ Main.AHPQ C:\\Users\\Axel9\\.julia\\dev\\AHPQ\\src\\quantizer\\quantizer.jl:14\n",
      "┌ Info: Iteration loss: 0.5554424237301258\tUpdate distance:0.2570595637738113\n",
      "└ @ Main.AHPQ C:\\Users\\Axel9\\.julia\\dev\\AHPQ\\src\\quantizer\\quantizer.jl:27\n",
      "┌ Info: Iteration loss: 0.49642686619838744\tUpdate distance:0.11935739333604369\n",
      "└ @ Main.AHPQ C:\\Users\\Axel9\\.julia\\dev\\AHPQ\\src\\quantizer\\quantizer.jl:27\n",
      "┌ Info: Product quantization converged after 2 iterations\n",
      "└ @ Main.AHPQ C:\\Users\\Axel9\\.julia\\dev\\AHPQ\\src\\quantizer\\quantizer.jl:30\n",
      "┌ Info: Starting incremental initialisation...\n",
      "└ @ Main.AHPQ C:\\Users\\Axel9\\.julia\\dev\\AHPQ\\src\\builder.jl:73\n",
      "┌ Info: \n",
      "│ \n",
      "│ Fitting quantizer on 20 data points...\n",
      "└ @ Main.AHPQ C:\\Users\\Axel9\\.julia\\dev\\AHPQ\\src\\quantizer\\quantizer.jl:74\n",
      "┌ Info: Starting Anisotropic Quantization...\n",
      "└ @ Main.AHPQ C:\\Users\\Axel9\\.julia\\dev\\AHPQ\\src\\quantizer\\quantizer.jl:38\n",
      "┌ Warning: Singular Matrix encountered, some clusters do not contain assignments.\n",
      "│ This happens when the number of clusters is relatively high ccompared to the number of data points.\n",
      "│ \n",
      "│ Optimisation method changed to Approximate\n",
      "└ @ Main.AHPQ C:\\Users\\Axel9\\.julia\\dev\\AHPQ\\src\\quantizer\\codebook_update_step.jl:238\n",
      "┌ Info: Iteration loss: 0.03978081390933754\tUpdate distance:0.43371480183226185\n",
      "└ @ Main.AHPQ C:\\Users\\Axel9\\.julia\\dev\\AHPQ\\src\\quantizer\\quantizer.jl:52\n",
      "┌ Warning: Singular Matrix encountered, some clusters do not contain assignments.\n",
      "│ This happens when the number of clusters is relatively high ccompared to the number of data points.\n",
      "│ \n",
      "│ Optimisation method changed to Approximate\n",
      "└ @ Main.AHPQ C:\\Users\\Axel9\\.julia\\dev\\AHPQ\\src\\quantizer\\codebook_update_step.jl:238\n",
      "┌ Info: Iteration loss: 0.018921411165241726\tUpdate distance:0.22939994007019826\n",
      "└ @ Main.AHPQ C:\\Users\\Axel9\\.julia\\dev\\AHPQ\\src\\quantizer\\quantizer.jl:52"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.08982639372512098\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "┌ Warning: Singular Matrix encountered, some clusters do not contain assignments.\n",
      "│ This happens when the number of clusters is relatively high ccompared to the number of data points.\n",
      "│ \n",
      "│ Optimisation method changed to Approximate\n",
      "└ @ Main.AHPQ C:\\Users\\Axel9\\.julia\\dev\\AHPQ\\src\\quantizer\\codebook_update_step.jl:238\n",
      "┌ Info: Iteration loss: 0.015567137681661883\tUpdate distance:0.053853975910621917\n",
      "└ @ Main.AHPQ C:\\Users\\Axel9\\.julia\\dev\\AHPQ\\src\\quantizer\\quantizer.jl:52\n",
      "┌ Info: Product quantization converged after 3 iterations\n",
      "└ @ Main.AHPQ C:\\Users\\Axel9\\.julia\\dev\\AHPQ\\src\\quantizer\\quantizer.jl:55\n",
      "┌ Info: \n",
      "│ \n",
      "│ Fitting quantizer on 200 data points...\n",
      "└ @ Main.AHPQ C:\\Users\\Axel9\\.julia\\dev\\AHPQ\\src\\quantizer\\quantizer.jl:79\n",
      "┌ Info: Starting Anisotropic Quantization...\n",
      "└ @ Main.AHPQ C:\\Users\\Axel9\\.julia\\dev\\AHPQ\\src\\quantizer\\quantizer.jl:38\n",
      "┌ Info: Iteration loss: 0.03429961920583804\tUpdate distance:0.3437035909870494\n",
      "└ @ Main.AHPQ C:\\Users\\Axel9\\.julia\\dev\\AHPQ\\src\\quantizer\\quantizer.jl:52\n",
      "┌ Info: Iteration loss: 0.02477292094572176\tUpdate distance:0.0906935471316557\n",
      "└ @ Main.AHPQ C:\\Users\\Axel9\\.julia\\dev\\AHPQ\\src\\quantizer\\quantizer.jl:52\n",
      "┌ Info: Product quantization converged after 2 iterations\n",
      "└ @ Main.AHPQ C:\\Users\\Axel9\\.julia\\dev\\AHPQ\\src\\quantizer\\quantizer.jl:55\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.05375743736835446\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Starting incremental initialisation...\n",
      "└ @ Main.AHPQ C:\\Users\\Axel9\\.julia\\dev\\AHPQ\\src\\builder.jl:73\n",
      "┌ Info: \n",
      "│ \n",
      "│ Fitting quantizer on 20 data points...\n",
      "└ @ Main.AHPQ C:\\Users\\Axel9\\.julia\\dev\\AHPQ\\src\\quantizer\\quantizer.jl:74\n",
      "┌ Info: Starting Anisotropic Quantization...\n",
      "└ @ Main.AHPQ C:\\Users\\Axel9\\.julia\\dev\\AHPQ\\src\\quantizer\\quantizer.jl:38\n",
      "┌ Info: Iteration loss: 0.024266994105027164\tUpdate distance:0.32296198915295776\n",
      "└ @ Main.AHPQ C:\\Users\\Axel9\\.julia\\dev\\AHPQ\\src\\quantizer\\quantizer.jl:52\n",
      "┌ Info: Iteration loss: 0.013081381540997888\tUpdate distance:0.0693422621659985\n",
      "└ @ Main.AHPQ C:\\Users\\Axel9\\.julia\\dev\\AHPQ\\src\\quantizer\\quantizer.jl:52\n",
      "┌ Info: Product quantization converged after 2 iterations\n",
      "└ @ Main.AHPQ C:\\Users\\Axel9\\.julia\\dev\\AHPQ\\src\\quantizer\\quantizer.jl:55\n",
      "┌ Info: \n",
      "│ \n",
      "│ Fitting quantizer on 200 data points...\n",
      "└ @ Main.AHPQ C:\\Users\\Axel9\\.julia\\dev\\AHPQ\\src\\quantizer\\quantizer.jl:79\n",
      "┌ Info: Starting Anisotropic Quantization...\n",
      "└ @ Main.AHPQ C:\\Users\\Axel9\\.julia\\dev\\AHPQ\\src\\quantizer\\quantizer.jl:38\n",
      "┌ Info: Iteration loss: 0.029689446364514233\tUpdate distance:0.2705220707531036\n",
      "└ @ Main.AHPQ C:\\Users\\Axel9\\.julia\\dev\\AHPQ\\src\\quantizer\\quantizer.jl:52\n",
      "┌ Info: Iteration loss: 0.022589723938916454\tUpdate distance:0.12385625310025011\n",
      "└ @ Main.AHPQ C:\\Users\\Axel9\\.julia\\dev\\AHPQ\\src\\quantizer\\quantizer.jl:52\n",
      "┌ Info: Product quantization converged after 2 iterations\n",
      "└ @ Main.AHPQ C:\\Users\\Axel9\\.julia\\dev\\AHPQ\\src\\quantizer\\quantizer.jl:55\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.26788585072220217\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Starting incremental initialisation...\n",
      "└ @ Main.AHPQ C:\\Users\\Axel9\\.julia\\dev\\AHPQ\\src\\builder.jl:73\n",
      "┌ Info: \n",
      "│ \n",
      "│ Fitting quantizer on 20 data points...\n",
      "└ @ Main.AHPQ C:\\Users\\Axel9\\.julia\\dev\\AHPQ\\src\\quantizer\\quantizer.jl:74\n",
      "┌ Info: Starting Anisotropic Quantization...\n",
      "└ @ Main.AHPQ C:\\Users\\Axel9\\.julia\\dev\\AHPQ\\src\\quantizer\\quantizer.jl:38\n",
      "┌ Info: Iteration loss: 0.017722817972153432\tUpdate distance:0.29446090190547364\n",
      "└ @ Main.AHPQ C:\\Users\\Axel9\\.julia\\dev\\AHPQ\\src\\quantizer\\quantizer.jl:52\n",
      "┌ Info: Iteration loss: 0.010454133111404031\tUpdate distance:0.15777919504934573\n",
      "└ @ Main.AHPQ C:\\Users\\Axel9\\.julia\\dev\\AHPQ\\src\\quantizer\\quantizer.jl:52\n",
      "┌ Info: Product quantization converged after 2 iterations\n",
      "└ @ Main.AHPQ C:\\Users\\Axel9\\.julia\\dev\\AHPQ\\src\\quantizer\\quantizer.jl:55\n",
      "┌ Info: \n",
      "│ \n",
      "│ Fitting quantizer on 200 data points...\n",
      "└ @ Main.AHPQ C:\\Users\\Axel9\\.julia\\dev\\AHPQ\\src\\quantizer\\quantizer.jl:79\n",
      "┌ Info: Starting Anisotropic Quantization...\n",
      "└ @ Main.AHPQ C:\\Users\\Axel9\\.julia\\dev\\AHPQ\\src\\quantizer\\quantizer.jl:38\n",
      "┌ Info: Iteration loss: 0.020794574531896946\tUpdate distance:0.2822948808284468\n",
      "└ @ Main.AHPQ C:\\Users\\Axel9\\.julia\\dev\\AHPQ\\src\\quantizer\\quantizer.jl:52\n",
      "┌ Info: Iteration loss: 0.01569587204906662\tUpdate distance:0.12452057954648667\n",
      "└ @ Main.AHPQ C:\\Users\\Axel9\\.julia\\dev\\AHPQ\\src\\quantizer\\quantizer.jl:52\n",
      "┌ Info: Product quantization converged after 2 iterations\n",
      "└ @ Main.AHPQ C:\\Users\\Axel9\\.julia\\dev\\AHPQ\\src\\quantizer\\quantizer.jl:55\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.07967566360627912\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Starting incremental initialisation...\n",
      "└ @ Main.AHPQ C:\\Users\\Axel9\\.julia\\dev\\AHPQ\\src\\builder.jl:73\n",
      "┌ Info: \n",
      "│ \n",
      "│ Fitting quantizer on 20 data points...\n",
      "└ @ Main.AHPQ C:\\Users\\Axel9\\.julia\\dev\\AHPQ\\src\\quantizer\\quantizer.jl:74\n",
      "┌ Info: Starting Anisotropic Quantization...\n",
      "└ @ Main.AHPQ C:\\Users\\Axel9\\.julia\\dev\\AHPQ\\src\\quantizer\\quantizer.jl:38\n",
      "┌ Info: Iteration loss: 0.013537444234937027\tUpdate distance:0.3270576250981443\n",
      "└ @ Main.AHPQ C:\\Users\\Axel9\\.julia\\dev\\AHPQ\\src\\quantizer\\quantizer.jl:52\n",
      "┌ Info: Iteration loss: 0.008120413401591173\tUpdate distance:0.16756463454294698\n",
      "└ @ Main.AHPQ C:\\Users\\Axel9\\.julia\\dev\\AHPQ\\src\\quantizer\\quantizer.jl:52\n",
      "┌ Info: Product quantization converged after 2 iterations\n",
      "└ @ Main.AHPQ C:\\Users\\Axel9\\.julia\\dev\\AHPQ\\src\\quantizer\\quantizer.jl:55\n",
      "┌ Info: \n",
      "│ \n",
      "│ Fitting quantizer on 200 data points...\n",
      "└ @ Main.AHPQ C:\\Users\\Axel9\\.julia\\dev\\AHPQ\\src\\quantizer\\quantizer.jl:79\n",
      "┌ Info: Starting Anisotropic Quantization...\n",
      "└ @ Main.AHPQ C:\\Users\\Axel9\\.julia\\dev\\AHPQ\\src\\quantizer\\quantizer.jl:38\n",
      "┌ Info: Iteration loss: 0.0148571681561652\tUpdate distance:0.3072171813304818\n",
      "└ @ Main.AHPQ C:\\Users\\Axel9\\.julia\\dev\\AHPQ\\src\\quantizer\\quantizer.jl:52\n",
      "┌ Info: Iteration loss: 0.010530384268360653\tUpdate distance:0.11989709726354628\n",
      "└ @ Main.AHPQ C:\\Users\\Axel9\\.julia\\dev\\AHPQ\\src\\quantizer\\quantizer.jl:52\n",
      "┌ Info: Product quantization converged after 2 iterations\n",
      "└ @ Main.AHPQ C:\\Users\\Axel9\\.julia\\dev\\AHPQ\\src\\quantizer\\quantizer.jl:55\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.33027457953479444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Starting incremental initialisation...\n",
      "└ @ Main.AHPQ C:\\Users\\Axel9\\.julia\\dev\\AHPQ\\src\\builder.jl:73\n",
      "┌ Info: \n",
      "│ \n",
      "│ Fitting quantizer on 20 data points...\n",
      "└ @ Main.AHPQ C:\\Users\\Axel9\\.julia\\dev\\AHPQ\\src\\quantizer\\quantizer.jl:74\n",
      "┌ Info: Starting Anisotropic Quantization...\n",
      "└ @ Main.AHPQ C:\\Users\\Axel9\\.julia\\dev\\AHPQ\\src\\quantizer\\quantizer.jl:38\n",
      "┌ Warning: Singular Matrix encountered, some clusters do not contain assignments.\n",
      "│ This happens when the number of clusters is relatively high ccompared to the number of data points.\n",
      "│ \n",
      "│ Optimisation method changed to Approximate\n",
      "└ @ Main.AHPQ C:\\Users\\Axel9\\.julia\\dev\\AHPQ\\src\\quantizer\\codebook_update_step.jl:238\n",
      "┌ Info: Iteration loss: 0.009923510178751116\tUpdate distance:0.3691781284172559\n",
      "└ @ Main.AHPQ C:\\Users\\Axel9\\.julia\\dev\\AHPQ\\src\\quantizer\\quantizer.jl:52\n",
      "┌ Warning: Singular Matrix encountered, some clusters do not contain assignments.\n",
      "│ This happens when the number of clusters is relatively high ccompared to the number of data points.\n",
      "│ \n",
      "│ Optimisation method changed to Approximate\n",
      "└ @ Main.AHPQ C:\\Users\\Axel9\\.julia\\dev\\AHPQ\\src\\quantizer\\codebook_update_step.jl:238\n",
      "┌ Info: Iteration loss: 0.004706744206525148\tUpdate distance:0.194690560119954\n",
      "└ @ Main.AHPQ C:\\Users\\Axel9\\.julia\\dev\\AHPQ\\src\\quantizer\\quantizer.jl:52\n",
      "┌ Info: Product quantization converged after 2 iterations\n",
      "└ @ Main.AHPQ C:\\Users\\Axel9\\.julia\\dev\\AHPQ\\src\\quantizer\\quantizer.jl:55\n",
      "┌ Info: \n",
      "│ \n",
      "│ Fitting quantizer on 200 data points...\n",
      "└ @ Main.AHPQ C:\\Users\\Axel9\\.julia\\dev\\AHPQ\\src\\quantizer\\quantizer.jl:79\n",
      "┌ Info: Starting Anisotropic Quantization...\n",
      "└ @ Main.AHPQ C:\\Users\\Axel9\\.julia\\dev\\AHPQ\\src\\quantizer\\quantizer.jl:38\n",
      "┌ Info: Iteration loss: 0.012318353096188455\tUpdate distance:0.3039928368608718\n",
      "└ @ Main.AHPQ C:\\Users\\Axel9\\.julia\\dev\\AHPQ\\src\\quantizer\\quantizer.jl:52\n",
      "┌ Info: Iteration loss: 0.008754804247165557\tUpdate distance:0.1410537590105979\n",
      "└ @ Main.AHPQ C:\\Users\\Axel9\\.julia\\dev\\AHPQ\\src\\quantizer\\quantizer.jl:52\n",
      "┌ Info: Product quantization converged after 2 iterations\n",
      "└ @ Main.AHPQ C:\\Users\\Axel9\\.julia\\dev\\AHPQ\\src\\quantizer\\quantizer.jl:55\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3396175137223145\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Starting incremental initialisation...\n",
      "└ @ Main.AHPQ C:\\Users\\Axel9\\.julia\\dev\\AHPQ\\src\\builder.jl:73\n",
      "┌ Info: \n",
      "│ \n",
      "│ Fitting quantizer on 20 data points...\n",
      "└ @ Main.AHPQ C:\\Users\\Axel9\\.julia\\dev\\AHPQ\\src\\quantizer\\quantizer.jl:74\n",
      "┌ Info: Starting Anisotropic Quantization...\n",
      "└ @ Main.AHPQ C:\\Users\\Axel9\\.julia\\dev\\AHPQ\\src\\quantizer\\quantizer.jl:38\n",
      "┌ Warning: Singular Matrix encountered, some clusters do not contain assignments.\n",
      "│ This happens when the number of clusters is relatively high ccompared to the number of data points.\n",
      "│ \n",
      "│ Optimisation method changed to Approximate\n",
      "└ @ Main.AHPQ C:\\Users\\Axel9\\.julia\\dev\\AHPQ\\src\\quantizer\\codebook_update_step.jl:238\n",
      "┌ Info: Iteration loss: 0.006173653321232376\tUpdate distance:0.3652505950602663\n",
      "└ @ Main.AHPQ C:\\Users\\Axel9\\.julia\\dev\\AHPQ\\src\\quantizer\\quantizer.jl:52\n",
      "┌ Warning: Singular Matrix encountered, some clusters do not contain assignments.\n",
      "│ This happens when the number of clusters is relatively high ccompared to the number of data points.\n",
      "│ \n",
      "│ Optimisation method changed to Approximate\n",
      "└ @ Main.AHPQ C:\\Users\\Axel9\\.julia\\dev\\AHPQ\\src\\quantizer\\codebook_update_step.jl:238\n",
      "┌ Info: Iteration loss: 0.003369964338084965\tUpdate distance:0.1667186343773052\n",
      "└ @ Main.AHPQ C:\\Users\\Axel9\\.julia\\dev\\AHPQ\\src\\quantizer\\quantizer.jl:52\n",
      "┌ Info: Product quantization converged after 2 iterations\n",
      "└ @ Main.AHPQ C:\\Users\\Axel9\\.julia\\dev\\AHPQ\\src\\quantizer\\quantizer.jl:55\n",
      "┌ Info: \n",
      "│ \n",
      "│ Fitting quantizer on 200 data points...\n",
      "└ @ Main.AHPQ C:\\Users\\Axel9\\.julia\\dev\\AHPQ\\src\\quantizer\\quantizer.jl:79\n",
      "┌ Info: Starting Anisotropic Quantization...\n",
      "└ @ Main.AHPQ C:\\Users\\Axel9\\.julia\\dev\\AHPQ\\src\\quantizer\\quantizer.jl:38\n",
      "┌ Info: Iteration loss: 0.006499324905519057\tUpdate distance:0.2514376272680502\n",
      "└ @ Main.AHPQ C:\\Users\\Axel9\\.julia\\dev\\AHPQ\\src\\quantizer\\quantizer.jl:52\n",
      "┌ Info: Iteration loss: 0.005136120110563656\tUpdate distance:0.10757183085201422\n",
      "└ @ Main.AHPQ C:\\Users\\Axel9\\.julia\\dev\\AHPQ\\src\\quantizer\\quantizer.jl:52\n",
      "┌ Info: Product quantization converged after 2 iterations\n",
      "└ @ Main.AHPQ C:\\Users\\Axel9\\.julia\\dev\\AHPQ\\src\\quantizer\\quantizer.jl:55\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.21241468962466395\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Starting incremental initialisation...\n",
      "└ @ Main.AHPQ C:\\Users\\Axel9\\.julia\\dev\\AHPQ\\src\\builder.jl:73\n",
      "┌ Info: \n",
      "│ \n",
      "│ Fitting quantizer on 20 data points...\n",
      "└ @ Main.AHPQ C:\\Users\\Axel9\\.julia\\dev\\AHPQ\\src\\quantizer\\quantizer.jl:74\n",
      "┌ Info: Starting Anisotropic Quantization...\n",
      "└ @ Main.AHPQ C:\\Users\\Axel9\\.julia\\dev\\AHPQ\\src\\quantizer\\quantizer.jl:38\n",
      "┌ Warning: Singular Matrix encountered, some clusters do not contain assignments.\n",
      "│ This happens when the number of clusters is relatively high ccompared to the number of data points.\n",
      "│ \n",
      "│ Optimisation method changed to Approximate\n",
      "└ @ Main.AHPQ C:\\Users\\Axel9\\.julia\\dev\\AHPQ\\src\\quantizer\\codebook_update_step.jl:238\n",
      "┌ Info: Iteration loss: 0.003948387063656031\tUpdate distance:0.4003766548576776\n",
      "└ @ Main.AHPQ C:\\Users\\Axel9\\.julia\\dev\\AHPQ\\src\\quantizer\\quantizer.jl:52\n",
      "┌ Warning: Singular Matrix encountered, some clusters do not contain assignments.\n",
      "│ This happens when the number of clusters is relatively high ccompared to the number of data points.\n",
      "│ \n",
      "│ Optimisation method changed to Approximate\n",
      "└ @ Main.AHPQ C:\\Users\\Axel9\\.julia\\dev\\AHPQ\\src\\quantizer\\codebook_update_step.jl:238\n",
      "┌ Info: Iteration loss: 0.0020853997379009933\tUpdate distance:0.14293523749139875\n",
      "└ @ Main.AHPQ C:\\Users\\Axel9\\.julia\\dev\\AHPQ\\src\\quantizer\\quantizer.jl:52\n",
      "┌ Info: Product quantization converged after 2 iterations\n",
      "└ @ Main.AHPQ C:\\Users\\Axel9\\.julia\\dev\\AHPQ\\src\\quantizer\\quantizer.jl:55\n",
      "┌ Info: \n",
      "│ \n",
      "│ Fitting quantizer on 200 data points...\n",
      "└ @ Main.AHPQ C:\\Users\\Axel9\\.julia\\dev\\AHPQ\\src\\quantizer\\quantizer.jl:79\n",
      "┌ Info: Starting Anisotropic Quantization...\n",
      "└ @ Main.AHPQ C:\\Users\\Axel9\\.julia\\dev\\AHPQ\\src\\quantizer\\quantizer.jl:38\n",
      "┌ Info: Iteration loss: 0.00510912757240159\tUpdate distance:0.26743535759825005\n",
      "└ @ Main.AHPQ C:\\Users\\Axel9\\.julia\\dev\\AHPQ\\src\\quantizer\\quantizer.jl:52\n",
      "┌ Info: Iteration loss: 0.003930933453075372\tUpdate distance:0.11852904318970398\n",
      "└ @ Main.AHPQ C:\\Users\\Axel9\\.julia\\dev\\AHPQ\\src\\quantizer\\quantizer.jl:52\n",
      "┌ Info: Product quantization converged after 2 iterations\n",
      "└ @ Main.AHPQ C:\\Users\\Axel9\\.julia\\dev\\AHPQ\\src\\quantizer\\quantizer.jl:55\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3218054738346564\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Starting incremental initialisation...\n",
      "└ @ Main.AHPQ C:\\Users\\Axel9\\.julia\\dev\\AHPQ\\src\\builder.jl:73\n",
      "┌ Info: \n",
      "│ \n",
      "│ Fitting quantizer on 20 data points...\n",
      "└ @ Main.AHPQ C:\\Users\\Axel9\\.julia\\dev\\AHPQ\\src\\quantizer\\quantizer.jl:74\n",
      "┌ Info: Starting Anisotropic Quantization...\n",
      "└ @ Main.AHPQ C:\\Users\\Axel9\\.julia\\dev\\AHPQ\\src\\quantizer\\quantizer.jl:38\n",
      "┌ Warning: Singular Matrix encountered, some clusters do not contain assignments.\n",
      "│ This happens when the number of clusters is relatively high ccompared to the number of data points.\n",
      "│ \n",
      "│ Optimisation method changed to Approximate\n",
      "└ @ Main.AHPQ C:\\Users\\Axel9\\.julia\\dev\\AHPQ\\src\\quantizer\\codebook_update_step.jl:238\n",
      "┌ Info: Iteration loss: 0.0022950026062931645\tUpdate distance:0.41018662946607426\n",
      "└ @ Main.AHPQ C:\\Users\\Axel9\\.julia\\dev\\AHPQ\\src\\quantizer\\quantizer.jl:52\n",
      "┌ Warning: Singular Matrix encountered, some clusters do not contain assignments.\n",
      "│ This happens when the number of clusters is relatively high ccompared to the number of data points.\n",
      "│ \n",
      "│ Optimisation method changed to Approximate\n",
      "└ @ Main.AHPQ C:\\Users\\Axel9\\.julia\\dev\\AHPQ\\src\\quantizer\\codebook_update_step.jl:238\n",
      "┌ Info: Iteration loss: 0.0014395532445998138\tUpdate distance:0.19531861839009015\n",
      "└ @ Main.AHPQ C:\\Users\\Axel9\\.julia\\dev\\AHPQ\\src\\quantizer\\quantizer.jl:52\n",
      "┌ Info: Product quantization converged after 2 iterations\n",
      "└ @ Main.AHPQ C:\\Users\\Axel9\\.julia\\dev\\AHPQ\\src\\quantizer\\quantizer.jl:55\n",
      "┌ Info: \n",
      "│ \n",
      "│ Fitting quantizer on 200 data points...\n",
      "└ @ Main.AHPQ C:\\Users\\Axel9\\.julia\\dev\\AHPQ\\src\\quantizer\\quantizer.jl:79\n",
      "┌ Info: Starting Anisotropic Quantization...\n",
      "└ @ Main.AHPQ C:\\Users\\Axel9\\.julia\\dev\\AHPQ\\src\\quantizer\\quantizer.jl:38\n",
      "┌ Info: Iteration loss: 0.0026958513257025886\tUpdate distance:0.23200970282220643\n",
      "└ @ Main.AHPQ C:\\Users\\Axel9\\.julia\\dev\\AHPQ\\src\\quantizer\\quantizer.jl:52\n",
      "┌ Info: Iteration loss: 0.0021913347624823443\tUpdate distance:0.07778543114622447\n",
      "└ @ Main.AHPQ C:\\Users\\Axel9\\.julia\\dev\\AHPQ\\src\\quantizer\\quantizer.jl:52\n",
      "┌ Info: Product quantization converged after 2 iterations\n",
      "└ @ Main.AHPQ C:\\Users\\Axel9\\.julia\\dev\\AHPQ\\src\\quantizer\\quantizer.jl:55\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.15511576339989613\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Starting incremental initialisation...\n",
      "└ @ Main.AHPQ C:\\Users\\Axel9\\.julia\\dev\\AHPQ\\src\\builder.jl:73\n",
      "┌ Info: \n",
      "│ \n",
      "│ Fitting quantizer on 20 data points...\n",
      "└ @ Main.AHPQ C:\\Users\\Axel9\\.julia\\dev\\AHPQ\\src\\quantizer\\quantizer.jl:74\n",
      "┌ Info: Starting Anisotropic Quantization...\n",
      "└ @ Main.AHPQ C:\\Users\\Axel9\\.julia\\dev\\AHPQ\\src\\quantizer\\quantizer.jl:38\n",
      "┌ Warning: Singular Matrix encountered, some clusters do not contain assignments.\n",
      "│ This happens when the number of clusters is relatively high ccompared to the number of data points.\n",
      "│ \n",
      "│ Optimisation method changed to Approximate\n",
      "└ @ Main.AHPQ C:\\Users\\Axel9\\.julia\\dev\\AHPQ\\src\\quantizer\\codebook_update_step.jl:238\n",
      "┌ Info: Iteration loss: 0.0008187153465438392\tUpdate distance:0.31194664732459143\n",
      "└ @ Main.AHPQ C:\\Users\\Axel9\\.julia\\dev\\AHPQ\\src\\quantizer\\quantizer.jl:52\n",
      "┌ Warning: Singular Matrix encountered, some clusters do not contain assignments.\n",
      "│ This happens when the number of clusters is relatively high ccompared to the number of data points.\n",
      "│ \n",
      "│ Optimisation method changed to Approximate\n",
      "└ @ Main.AHPQ C:\\Users\\Axel9\\.julia\\dev\\AHPQ\\src\\quantizer\\codebook_update_step.jl:238\n",
      "┌ Info: Iteration loss: 0.0005173541323340435\tUpdate distance:0.0005917745350726239\n",
      "└ @ Main.AHPQ C:\\Users\\Axel9\\.julia\\dev\\AHPQ\\src\\quantizer\\quantizer.jl:52\n",
      "┌ Info: Product quantization converged after 2 iterations\n",
      "└ @ Main.AHPQ C:\\Users\\Axel9\\.julia\\dev\\AHPQ\\src\\quantizer\\quantizer.jl:55\n",
      "┌ Info: \n",
      "│ \n",
      "│ Fitting quantizer on 200 data points...\n",
      "└ @ Main.AHPQ C:\\Users\\Axel9\\.julia\\dev\\AHPQ\\src\\quantizer\\quantizer.jl:79\n",
      "┌ Info: Starting Anisotropic Quantization...\n",
      "└ @ Main.AHPQ C:\\Users\\Axel9\\.julia\\dev\\AHPQ\\src\\quantizer\\quantizer.jl:38\n",
      "┌ Info: Iteration loss: 0.001233949888214585\tUpdate distance:0.22015018799996308\n",
      "└ @ Main.AHPQ C:\\Users\\Axel9\\.julia\\dev\\AHPQ\\src\\quantizer\\quantizer.jl:52\n",
      "┌ Info: Iteration loss: 0.0010527555662842281\tUpdate distance:0.08718948169298812\n",
      "└ @ Main.AHPQ C:\\Users\\Axel9\\.julia\\dev\\AHPQ\\src\\quantizer\\quantizer.jl:52\n",
      "┌ Info: Product quantization converged after 2 iterations\n",
      "└ @ Main.AHPQ C:\\Users\\Axel9\\.julia\\dev\\AHPQ\\src\\quantizer\\quantizer.jl:55\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.38362411479926933\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Starting incremental initialisation...\n",
      "└ @ Main.AHPQ C:\\Users\\Axel9\\.julia\\dev\\AHPQ\\src\\builder.jl:73\n",
      "┌ Info: \n",
      "│ \n",
      "│ Fitting quantizer on 20 data points...\n",
      "└ @ Main.AHPQ C:\\Users\\Axel9\\.julia\\dev\\AHPQ\\src\\quantizer\\quantizer.jl:74\n",
      "┌ Info: Starting Anisotropic Quantization...\n",
      "└ @ Main.AHPQ C:\\Users\\Axel9\\.julia\\dev\\AHPQ\\src\\quantizer\\quantizer.jl:38\n",
      "┌ Warning: Singular Matrix encountered, some clusters do not contain assignments.\n",
      "│ This happens when the number of clusters is relatively high ccompared to the number of data points.\n",
      "│ \n",
      "│ Optimisation method changed to Approximate\n",
      "└ @ Main.AHPQ C:\\Users\\Axel9\\.julia\\dev\\AHPQ\\src\\quantizer\\codebook_update_step.jl:238\n",
      "┌ Info: Iteration loss: 1.826712148003534e-6\tUpdate distance:0.0005835346761209465\n",
      "└ @ Main.AHPQ C:\\Users\\Axel9\\.julia\\dev\\AHPQ\\src\\quantizer\\quantizer.jl:52\n",
      "┌ Info: Product quantization converged after 1 iterations\n",
      "└ @ Main.AHPQ C:\\Users\\Axel9\\.julia\\dev\\AHPQ\\src\\quantizer\\quantizer.jl:55\n",
      "┌ Info: \n",
      "│ \n",
      "│ Fitting quantizer on 200 data points...\n",
      "└ @ Main.AHPQ C:\\Users\\Axel9\\.julia\\dev\\AHPQ\\src\\quantizer\\quantizer.jl:79\n",
      "┌ Info: Starting Anisotropic Quantization...\n",
      "└ @ Main.AHPQ C:\\Users\\Axel9\\.julia\\dev\\AHPQ\\src\\quantizer\\quantizer.jl:38\n",
      "┌ Info: Iteration loss: 2.35483404926202e-6\tUpdate distance:0.07211783107450379\n",
      "└ @ Main.AHPQ C:\\Users\\Axel9\\.julia\\dev\\AHPQ\\src\\quantizer\\quantizer.jl:52\n",
      "┌ Info: Product quantization converged after 1 iterations\n",
      "└ @ Main.AHPQ C:\\Users\\Axel9\\.julia\\dev\\AHPQ\\src\\quantizer\\quantizer.jl:55\n"
     ]
    }
   ],
   "source": [
    "Ts = 0:0.1:1\n",
    "scores = zeros(11)\n",
    "for i in 1:length(Ts)\n",
    "    traindata=deepcopy(data)\n",
    "    ahpq = builder(traindata; T=Ts[i], n_codebooks=n_codebooks, \n",
    "                                    n_centers=n_centers,\n",
    "                                    verbose=true,\n",
    "                                    stopcond=stopcond,\n",
    "                                    a=0,\n",
    "                                    training_points=200,\n",
    "                                    increment_steps=2)\n",
    "    yhat = AHPQ.MIPS(ahpq, queries, n_neighbors)\n",
    "    scores[i] = recall1atN(yhat, groundtruth, recalln)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-08T18:39:45.238000+01:00",
     "start_time": "2021-02-08T17:39:45.209Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"utf-8\"?>\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"600\" height=\"400\" viewBox=\"0 0 2400 1600\">\n",
       "<defs>\n",
       "  <clipPath id=\"clip100\">\n",
       "    <rect x=\"0\" y=\"0\" width=\"2400\" height=\"1600\"/>\n",
       "  </clipPath>\n",
       "</defs>\n",
       "<path clip-path=\"url(#clip100)\" d=\"\n",
       "M0 1600 L2400 1600 L2400 0 L0 0  Z\n",
       "  \" fill=\"#ffffff\" fill-rule=\"evenodd\" fill-opacity=\"1\"/>\n",
       "<defs>\n",
       "  <clipPath id=\"clip101\">\n",
       "    <rect x=\"480\" y=\"0\" width=\"1681\" height=\"1600\"/>\n",
       "  </clipPath>\n",
       "</defs>\n",
       "<path clip-path=\"url(#clip100)\" d=\"\n",
       "M211.602 1423.18 L2352.76 1423.18 L2352.76 123.472 L211.602 123.472  Z\n",
       "  \" fill=\"#ffffff\" fill-rule=\"evenodd\" fill-opacity=\"1\"/>\n",
       "<defs>\n",
       "  <clipPath id=\"clip102\">\n",
       "    <rect x=\"211\" y=\"123\" width=\"2142\" height=\"1301\"/>\n",
       "  </clipPath>\n",
       "</defs>\n",
       "<polyline clip-path=\"url(#clip102)\" style=\"stroke:#000000; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  496.641,1423.18 496.641,123.472 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip102)\" style=\"stroke:#000000; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  945.52,1423.18 945.52,123.472 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip102)\" style=\"stroke:#000000; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  1394.4,1423.18 1394.4,123.472 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip102)\" style=\"stroke:#000000; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  1843.28,1423.18 1843.28,123.472 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip102)\" style=\"stroke:#000000; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  2292.16,1423.18 2292.16,123.472 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip100)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  211.602,1423.18 2352.76,1423.18 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip100)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  496.641,1423.18 496.641,1407.58 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip100)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  945.52,1423.18 945.52,1407.58 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip100)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  1394.4,1423.18 1394.4,1407.58 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip100)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  1843.28,1423.18 1843.28,1407.58 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip100)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  2292.16,1423.18 2292.16,1407.58 \n",
       "  \"/>\n",
       "<path clip-path=\"url(#clip100)\" d=\"M 0 0 M478.956 1452.37 Q475.344 1452.37 473.516 1455.94 Q471.71 1459.48 471.71 1466.61 Q471.71 1473.71 473.516 1477.28 Q475.344 1480.82 478.956 1480.82 Q482.59 1480.82 484.395 1477.28 Q486.224 1473.71 486.224 1466.61 Q486.224 1459.48 484.395 1455.94 Q482.59 1452.37 478.956 1452.37 M478.956 1448.67 Q484.766 1448.67 487.821 1453.27 Q490.9 1457.86 490.9 1466.61 Q490.9 1475.33 487.821 1479.94 Q484.766 1484.52 478.956 1484.52 Q473.145 1484.52 470.067 1479.94 Q467.011 1475.33 467.011 1466.61 Q467.011 1457.86 470.067 1453.27 Q473.145 1448.67 478.956 1448.67 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip100)\" d=\"M 0 0 M495.969 1477.97 L500.854 1477.97 L500.854 1483.85 L495.969 1483.85 L495.969 1477.97 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip100)\" d=\"M 0 0 M509.951 1479.92 L526.27 1479.92 L526.27 1483.85 L504.326 1483.85 L504.326 1479.92 Q506.988 1477.16 511.571 1472.53 Q516.178 1467.88 517.358 1466.54 Q519.604 1464.01 520.483 1462.28 Q521.386 1460.52 521.386 1458.83 Q521.386 1456.07 519.441 1454.34 Q517.52 1452.6 514.418 1452.6 Q512.219 1452.6 509.766 1453.37 Q507.335 1454.13 504.557 1455.68 L504.557 1450.96 Q507.381 1449.82 509.835 1449.25 Q512.289 1448.67 514.326 1448.67 Q519.696 1448.67 522.891 1451.35 Q526.085 1454.04 526.085 1458.53 Q526.085 1460.66 525.275 1462.58 Q524.488 1464.48 522.381 1467.07 Q521.803 1467.74 518.701 1470.96 Q515.599 1474.15 509.951 1479.92 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip100)\" d=\"M 0 0 M926.793 1452.37 Q923.182 1452.37 921.353 1455.94 Q919.548 1459.48 919.548 1466.61 Q919.548 1473.71 921.353 1477.28 Q923.182 1480.82 926.793 1480.82 Q930.427 1480.82 932.233 1477.28 Q934.062 1473.71 934.062 1466.61 Q934.062 1459.48 932.233 1455.94 Q930.427 1452.37 926.793 1452.37 M926.793 1448.67 Q932.603 1448.67 935.659 1453.27 Q938.737 1457.86 938.737 1466.61 Q938.737 1475.33 935.659 1479.94 Q932.603 1484.52 926.793 1484.52 Q920.983 1484.52 917.904 1479.94 Q914.849 1475.33 914.849 1466.61 Q914.849 1457.86 917.904 1453.27 Q920.983 1448.67 926.793 1448.67 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip100)\" d=\"M 0 0 M943.807 1477.97 L948.691 1477.97 L948.691 1483.85 L943.807 1483.85 L943.807 1477.97 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip100)\" d=\"M 0 0 M966.608 1453.37 L954.802 1471.81 L966.608 1471.81 L966.608 1453.37 M965.381 1449.29 L971.26 1449.29 L971.26 1471.81 L976.191 1471.81 L976.191 1475.7 L971.26 1475.7 L971.26 1483.85 L966.608 1483.85 L966.608 1475.7 L951.006 1475.7 L951.006 1471.19 L965.381 1449.29 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip100)\" d=\"M 0 0 M1375.83 1452.37 Q1372.22 1452.37 1370.39 1455.94 Q1368.59 1459.48 1368.59 1466.61 Q1368.59 1473.71 1370.39 1477.28 Q1372.22 1480.82 1375.83 1480.82 Q1379.47 1480.82 1381.27 1477.28 Q1383.1 1473.71 1383.1 1466.61 Q1383.1 1459.48 1381.27 1455.94 Q1379.47 1452.37 1375.83 1452.37 M1375.83 1448.67 Q1381.64 1448.67 1384.7 1453.27 Q1387.78 1457.86 1387.78 1466.61 Q1387.78 1475.33 1384.7 1479.94 Q1381.64 1484.52 1375.83 1484.52 Q1370.02 1484.52 1366.95 1479.94 Q1363.89 1475.33 1363.89 1466.61 Q1363.89 1457.86 1366.95 1453.27 Q1370.02 1448.67 1375.83 1448.67 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip100)\" d=\"M 0 0 M1392.85 1477.97 L1397.73 1477.97 L1397.73 1483.85 L1392.85 1483.85 L1392.85 1477.97 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip100)\" d=\"M 0 0 M1413.38 1464.71 Q1410.23 1464.71 1408.38 1466.86 Q1406.55 1469.01 1406.55 1472.76 Q1406.55 1476.49 1408.38 1478.67 Q1410.23 1480.82 1413.38 1480.82 Q1416.53 1480.82 1418.36 1478.67 Q1420.21 1476.49 1420.21 1472.76 Q1420.21 1469.01 1418.36 1466.86 Q1416.53 1464.71 1413.38 1464.71 M1422.66 1450.06 L1422.66 1454.31 Q1420.9 1453.48 1419.1 1453.04 Q1417.32 1452.6 1415.56 1452.6 Q1410.93 1452.6 1408.47 1455.73 Q1406.04 1458.85 1405.7 1465.17 Q1407.06 1463.16 1409.12 1462.09 Q1411.18 1461 1413.66 1461 Q1418.87 1461 1421.88 1464.18 Q1424.91 1467.32 1424.91 1472.76 Q1424.91 1478.09 1421.76 1481.31 Q1418.61 1484.52 1413.38 1484.52 Q1407.38 1484.52 1404.21 1479.94 Q1401.04 1475.33 1401.04 1466.61 Q1401.04 1458.41 1404.93 1453.55 Q1408.82 1448.67 1415.37 1448.67 Q1417.13 1448.67 1418.91 1449.01 Q1420.72 1449.36 1422.66 1450.06 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip100)\" d=\"M 0 0 M1824.84 1452.37 Q1821.23 1452.37 1819.4 1455.94 Q1817.6 1459.48 1817.6 1466.61 Q1817.6 1473.71 1819.4 1477.28 Q1821.23 1480.82 1824.84 1480.82 Q1828.47 1480.82 1830.28 1477.28 Q1832.11 1473.71 1832.11 1466.61 Q1832.11 1459.48 1830.28 1455.94 Q1828.47 1452.37 1824.84 1452.37 M1824.84 1448.67 Q1830.65 1448.67 1833.71 1453.27 Q1836.79 1457.86 1836.79 1466.61 Q1836.79 1475.33 1833.71 1479.94 Q1830.65 1484.52 1824.84 1484.52 Q1819.03 1484.52 1815.95 1479.94 Q1812.9 1475.33 1812.9 1466.61 Q1812.9 1457.86 1815.95 1453.27 Q1819.03 1448.67 1824.84 1448.67 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip100)\" d=\"M 0 0 M1841.85 1477.97 L1846.74 1477.97 L1846.74 1483.85 L1841.85 1483.85 L1841.85 1477.97 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip100)\" d=\"M 0 0 M1861.81 1467.44 Q1858.47 1467.44 1856.55 1469.22 Q1854.66 1471 1854.66 1474.13 Q1854.66 1477.25 1856.55 1479.04 Q1858.47 1480.82 1861.81 1480.82 Q1865.14 1480.82 1867.06 1479.04 Q1868.98 1477.23 1868.98 1474.13 Q1868.98 1471 1867.06 1469.22 Q1865.16 1467.44 1861.81 1467.44 M1857.13 1465.45 Q1854.12 1464.71 1852.43 1462.65 Q1850.77 1460.59 1850.77 1457.63 Q1850.77 1453.48 1853.71 1451.07 Q1856.67 1448.67 1861.81 1448.67 Q1866.97 1448.67 1869.91 1451.07 Q1872.85 1453.48 1872.85 1457.63 Q1872.85 1460.59 1871.16 1462.65 Q1869.49 1464.71 1866.51 1465.45 Q1869.89 1466.24 1871.76 1468.53 Q1873.66 1470.82 1873.66 1474.13 Q1873.66 1479.15 1870.58 1481.84 Q1867.53 1484.52 1861.81 1484.52 Q1856.09 1484.52 1853.01 1481.84 Q1849.96 1479.15 1849.96 1474.13 Q1849.96 1470.82 1851.85 1468.53 Q1853.75 1466.24 1857.13 1465.45 M1855.42 1458.06 Q1855.42 1460.75 1857.09 1462.25 Q1858.78 1463.76 1861.81 1463.76 Q1864.82 1463.76 1866.51 1462.25 Q1868.22 1460.75 1868.22 1458.06 Q1868.22 1455.38 1866.51 1453.88 Q1864.82 1452.37 1861.81 1452.37 Q1858.78 1452.37 1857.09 1453.88 Q1855.42 1455.38 1855.42 1458.06 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip100)\" d=\"M 0 0 M2264.06 1479.92 L2271.69 1479.92 L2271.69 1453.55 L2263.38 1455.22 L2263.38 1450.96 L2271.65 1449.29 L2276.32 1449.29 L2276.32 1479.92 L2283.96 1479.92 L2283.96 1483.85 L2264.06 1483.85 L2264.06 1479.92 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip100)\" d=\"M 0 0 M2289.03 1477.97 L2293.92 1477.97 L2293.92 1483.85 L2289.03 1483.85 L2289.03 1477.97 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip100)\" d=\"M 0 0 M2308.99 1452.37 Q2305.37 1452.37 2303.55 1455.94 Q2301.74 1459.48 2301.74 1466.61 Q2301.74 1473.71 2303.55 1477.28 Q2305.37 1480.82 2308.99 1480.82 Q2312.62 1480.82 2314.43 1477.28 Q2316.25 1473.71 2316.25 1466.61 Q2316.25 1459.48 2314.43 1455.94 Q2312.62 1452.37 2308.99 1452.37 M2308.99 1448.67 Q2314.8 1448.67 2317.85 1453.27 Q2320.93 1457.86 2320.93 1466.61 Q2320.93 1475.33 2317.85 1479.94 Q2314.8 1484.52 2308.99 1484.52 Q2303.18 1484.52 2300.1 1479.94 Q2297.04 1475.33 2297.04 1466.61 Q2297.04 1457.86 2300.1 1453.27 Q2303.18 1448.67 2308.99 1448.67 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip100)\" d=\"M 0 0 M1262.08 1508.52 L1302.28 1508.52 L1302.28 1513.93 L1285.41 1513.93 L1285.41 1556.04 L1278.95 1556.04 L1278.95 1513.93 L1262.08 1513.93 L1262.08 1508.52 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><polyline clip-path=\"url(#clip102)\" style=\"stroke:#000000; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  211.602,1179.58 2352.76,1179.58 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip102)\" style=\"stroke:#000000; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  211.602,884.122 2352.76,884.122 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip102)\" style=\"stroke:#000000; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  211.602,588.666 2352.76,588.666 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip102)\" style=\"stroke:#000000; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  211.602,293.211 2352.76,293.211 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip100)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  211.602,1423.18 211.602,123.472 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip100)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  211.602,1179.58 237.296,1179.58 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip100)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  211.602,884.122 237.296,884.122 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip100)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  211.602,588.666 237.296,588.666 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip100)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  211.602,293.211 237.296,293.211 \n",
       "  \"/>\n",
       "<path clip-path=\"url(#clip100)\" d=\"M 0 0 M128.288 1165.38 Q124.677 1165.38 122.848 1168.94 Q121.043 1172.48 121.043 1179.61 Q121.043 1186.72 122.848 1190.28 Q124.677 1193.82 128.288 1193.82 Q131.922 1193.82 133.728 1190.28 Q135.556 1186.72 135.556 1179.61 Q135.556 1172.48 133.728 1168.94 Q131.922 1165.38 128.288 1165.38 M128.288 1161.67 Q134.098 1161.67 137.154 1166.28 Q140.232 1170.86 140.232 1179.61 Q140.232 1188.34 137.154 1192.94 Q134.098 1197.53 128.288 1197.53 Q122.478 1197.53 119.399 1192.94 Q116.343 1188.34 116.343 1179.61 Q116.343 1170.86 119.399 1166.28 Q122.478 1161.67 128.288 1161.67 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip100)\" d=\"M 0 0 M145.302 1190.98 L150.186 1190.98 L150.186 1196.86 L145.302 1196.86 L145.302 1190.98 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip100)\" d=\"M 0 0 M159.283 1192.92 L175.602 1192.92 L175.602 1196.86 L153.658 1196.86 L153.658 1192.92 Q156.32 1190.17 160.903 1185.54 Q165.51 1180.88 166.69 1179.54 Q168.936 1177.02 169.815 1175.28 Q170.718 1173.52 170.718 1171.83 Q170.718 1169.08 168.774 1167.34 Q166.852 1165.61 163.751 1165.61 Q161.552 1165.61 159.098 1166.37 Q156.667 1167.13 153.89 1168.69 L153.89 1163.96 Q156.714 1162.83 159.167 1162.25 Q161.621 1161.67 163.658 1161.67 Q169.028 1161.67 172.223 1164.36 Q175.417 1167.04 175.417 1171.53 Q175.417 1173.66 174.607 1175.58 Q173.82 1177.48 171.714 1180.07 Q171.135 1180.75 168.033 1183.96 Q164.931 1187.16 159.283 1192.92 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip100)\" d=\"M 0 0 M126.205 869.92 Q122.593 869.92 120.765 873.485 Q118.959 877.027 118.959 884.156 Q118.959 891.263 120.765 894.828 Q122.593 898.369 126.205 898.369 Q129.839 898.369 131.644 894.828 Q133.473 891.263 133.473 884.156 Q133.473 877.027 131.644 873.485 Q129.839 869.92 126.205 869.92 M126.205 866.217 Q132.015 866.217 135.07 870.823 Q138.149 875.406 138.149 884.156 Q138.149 892.883 135.07 897.49 Q132.015 902.073 126.205 902.073 Q120.394 902.073 117.316 897.49 Q114.26 892.883 114.26 884.156 Q114.26 875.406 117.316 870.823 Q120.394 866.217 126.205 866.217 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip100)\" d=\"M 0 0 M143.218 895.522 L148.103 895.522 L148.103 901.402 L143.218 901.402 L143.218 895.522 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip100)\" d=\"M 0 0 M166.019 870.916 L154.214 889.365 L166.019 889.365 L166.019 870.916 M164.792 866.842 L170.672 866.842 L170.672 889.365 L175.602 889.365 L175.602 893.254 L170.672 893.254 L170.672 901.402 L166.019 901.402 L166.019 893.254 L150.417 893.254 L150.417 888.74 L164.792 866.842 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip100)\" d=\"M 0 0 M126.529 574.465 Q122.918 574.465 121.089 578.03 Q119.283 581.572 119.283 588.701 Q119.283 595.808 121.089 599.372 Q122.918 602.914 126.529 602.914 Q130.163 602.914 131.968 599.372 Q133.797 595.808 133.797 588.701 Q133.797 581.572 131.968 578.03 Q130.163 574.465 126.529 574.465 M126.529 570.761 Q132.339 570.761 135.394 575.368 Q138.473 579.951 138.473 588.701 Q138.473 597.428 135.394 602.034 Q132.339 606.618 126.529 606.618 Q120.718 606.618 117.64 602.034 Q114.584 597.428 114.584 588.701 Q114.584 579.951 117.64 575.368 Q120.718 570.761 126.529 570.761 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip100)\" d=\"M 0 0 M143.542 600.067 L148.427 600.067 L148.427 605.946 L143.542 605.946 L143.542 600.067 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip100)\" d=\"M 0 0 M164.075 586.803 Q160.927 586.803 159.075 588.956 Q157.246 591.109 157.246 594.859 Q157.246 598.585 159.075 600.761 Q160.927 602.914 164.075 602.914 Q167.223 602.914 169.052 600.761 Q170.903 598.585 170.903 594.859 Q170.903 591.109 169.052 588.956 Q167.223 586.803 164.075 586.803 M173.357 572.15 L173.357 576.41 Q171.598 575.576 169.792 575.136 Q168.01 574.697 166.251 574.697 Q161.621 574.697 159.167 577.822 Q156.737 580.947 156.39 587.266 Q157.755 585.252 159.815 584.187 Q161.876 583.099 164.352 583.099 Q169.561 583.099 172.57 586.271 Q175.602 589.419 175.602 594.859 Q175.602 600.183 172.454 603.4 Q169.306 606.618 164.075 606.618 Q158.079 606.618 154.908 602.034 Q151.737 597.428 151.737 588.701 Q151.737 580.507 155.626 575.646 Q159.515 570.761 166.065 570.761 Q167.825 570.761 169.607 571.109 Q171.413 571.456 173.357 572.15 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip100)\" d=\"M 0 0 M126.783 279.01 Q123.172 279.01 121.343 282.575 Q119.538 286.116 119.538 293.246 Q119.538 300.352 121.343 303.917 Q123.172 307.459 126.783 307.459 Q130.417 307.459 132.223 303.917 Q134.052 300.352 134.052 293.246 Q134.052 286.116 132.223 282.575 Q130.417 279.01 126.783 279.01 M126.783 275.306 Q132.593 275.306 135.649 279.913 Q138.728 284.496 138.728 293.246 Q138.728 301.973 135.649 306.579 Q132.593 311.162 126.783 311.162 Q120.973 311.162 117.894 306.579 Q114.839 301.973 114.839 293.246 Q114.839 284.496 117.894 279.913 Q120.973 275.306 126.783 275.306 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip100)\" d=\"M 0 0 M143.797 304.612 L148.681 304.612 L148.681 310.491 L143.797 310.491 L143.797 304.612 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip100)\" d=\"M 0 0 M163.751 294.079 Q160.417 294.079 158.496 295.862 Q156.598 297.644 156.598 300.769 Q156.598 303.894 158.496 305.676 Q160.417 307.459 163.751 307.459 Q167.084 307.459 169.005 305.676 Q170.927 303.871 170.927 300.769 Q170.927 297.644 169.005 295.862 Q167.107 294.079 163.751 294.079 M159.075 292.088 Q156.065 291.348 154.376 289.288 Q152.709 287.227 152.709 284.264 Q152.709 280.121 155.649 277.714 Q158.612 275.306 163.751 275.306 Q168.913 275.306 171.852 277.714 Q174.792 280.121 174.792 284.264 Q174.792 287.227 173.102 289.288 Q171.436 291.348 168.45 292.088 Q171.829 292.876 173.704 295.167 Q175.602 297.459 175.602 300.769 Q175.602 305.792 172.524 308.477 Q169.468 311.162 163.751 311.162 Q158.033 311.162 154.954 308.477 Q151.899 305.792 151.899 300.769 Q151.899 297.459 153.797 295.167 Q155.695 292.876 159.075 292.088 M157.362 284.704 Q157.362 287.389 159.028 288.894 Q160.718 290.399 163.751 290.399 Q166.76 290.399 168.45 288.894 Q170.163 287.389 170.163 284.704 Q170.163 282.019 168.45 280.514 Q166.76 279.01 163.751 279.01 Q160.718 279.01 159.028 280.514 Q157.362 282.019 157.362 284.704 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip100)\" d=\"M 0 0 M65.7242 925.514 Q66.4244 923.445 68.7161 921.504 Q71.0077 919.53 75.0181 917.557 L88.0042 911.032 L88.0042 917.939 L75.8138 924.018 Q71.0395 926.373 69.48 928.601 Q67.9204 930.798 67.9204 934.617 L67.9204 941.619 L88.0042 941.619 L88.0042 948.049 L40.4842 948.049 L40.4842 933.535 Q40.4842 925.387 43.8898 921.376 Q47.2955 917.366 54.1704 917.366 Q58.6582 917.366 61.6183 919.467 Q64.5784 921.536 65.7242 925.514 M45.7677 941.619 L62.6368 941.619 L62.6368 933.535 Q62.6368 928.888 60.5043 926.533 Q58.34 924.145 54.1704 924.145 Q50.0009 924.145 47.9002 926.533 Q45.7677 928.888 45.7677 933.535 L45.7677 941.619 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip100)\" d=\"M 0 0 M68.7161 877.326 L71.5806 877.326 L71.5806 904.253 Q77.6281 903.871 80.8109 900.624 Q83.9619 897.346 83.9619 891.521 Q83.9619 888.147 83.1344 884.996 Q82.3069 881.814 80.6518 878.694 L86.1899 878.694 Q87.5267 881.845 88.227 885.156 Q88.9272 888.466 88.9272 891.871 Q88.9272 900.401 83.9619 905.398 Q78.9967 910.364 70.5303 910.364 Q61.7774 910.364 56.6531 905.653 Q51.4968 900.911 51.4968 892.89 Q51.4968 885.697 56.1438 881.527 Q60.7589 877.326 68.7161 877.326 M66.9973 883.182 Q62.1912 883.246 59.3266 885.888 Q56.4621 888.498 56.4621 892.826 Q56.4621 897.728 59.2312 900.688 Q62.0002 903.616 67.0292 904.062 L66.9973 883.182 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip100)\" d=\"M 0 0 M53.7248 845.529 L59.1993 845.529 Q57.8307 848.012 57.1623 850.526 Q56.4621 853.009 56.4621 855.555 Q56.4621 861.252 60.0905 864.403 Q63.6872 867.554 70.212 867.554 Q76.7369 867.554 80.3653 864.403 Q83.9619 861.252 83.9619 855.555 Q83.9619 853.009 83.2935 850.526 Q82.5933 848.012 81.2247 845.529 L86.6355 845.529 Q87.7814 847.98 88.3543 850.622 Q88.9272 853.232 88.9272 856.192 Q88.9272 864.244 83.8664 868.987 Q78.8057 873.729 70.212 873.729 Q61.491 873.729 56.4939 868.955 Q51.4968 864.149 51.4968 855.81 Q51.4968 853.104 52.0697 850.526 Q52.6108 847.948 53.7248 845.529 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip100)\" d=\"M 0 0 M70.0847 823.185 Q70.0847 830.283 71.7079 833.02 Q73.3312 835.758 77.2461 835.758 Q80.3653 835.758 82.2114 833.721 Q84.0256 831.652 84.0256 828.119 Q84.0256 823.249 80.5881 820.321 Q77.1188 817.361 71.3897 817.361 L70.0847 817.361 L70.0847 823.185 M67.6657 811.504 L88.0042 811.504 L88.0042 817.361 L82.5933 817.361 Q85.8398 819.366 87.3994 822.358 Q88.9272 825.35 88.9272 829.678 Q88.9272 835.153 85.8716 838.399 Q82.7843 841.614 77.6281 841.614 Q71.6125 841.614 68.5569 837.604 Q65.5014 833.561 65.5014 825.573 L65.5014 817.361 L64.9285 817.361 Q60.8862 817.361 58.6901 820.034 Q56.4621 822.676 56.4621 827.482 Q56.4621 830.538 57.1941 833.434 Q57.9262 836.331 59.3903 839.004 L53.9795 839.004 Q52.7381 835.789 52.1334 832.766 Q51.4968 829.742 51.4968 826.877 Q51.4968 819.143 55.5072 815.324 Q59.5176 811.504 67.6657 811.504 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip100)\" d=\"M 0 0 M38.479 805.361 L38.479 799.505 L88.0042 799.505 L88.0042 805.361 L38.479 805.361 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip100)\" d=\"M 0 0 M38.479 793.362 L38.479 787.506 L88.0042 787.506 L88.0042 793.362 L38.479 793.362 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip100)\" d=\"M 0 0 M82.5933 758.701 L82.5933 748.197 L46.3406 748.197 L48.6323 759.624 L42.7758 759.624 L40.4842 748.261 L40.4842 741.832 L82.5933 741.832 L82.5933 731.328 L88.0042 731.328 L88.0042 758.701 L82.5933 758.701 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip100)\" d=\"M 0 0 M70.9122 707.075 Q75.4637 707.075 78.0737 704.815 Q80.6518 702.555 80.6518 698.609 Q80.6518 694.694 78.0418 692.466 Q75.4319 690.206 70.9122 690.206 Q66.4562 690.206 63.8463 692.497 Q61.2045 694.789 61.2045 698.672 Q61.2045 702.523 63.8145 704.815 Q66.4244 707.075 70.9122 707.075 M80.429 689.728 Q82.8798 691.638 84.0574 694.121 Q85.2032 696.571 85.2032 699.85 Q85.2032 705.324 81.2565 708.762 Q77.2779 712.167 70.9122 712.167 Q64.5465 712.167 60.568 708.73 Q56.5894 705.292 56.5894 699.85 Q56.5894 696.571 57.7989 694.089 Q58.9765 691.606 61.3955 689.728 L57.226 689.728 L57.226 685.177 L80.6518 685.177 Q79.9515 680.53 76.4186 677.92 Q72.8538 675.278 67.2201 675.278 Q63.8145 675.278 60.8226 676.297 Q57.8307 677.283 55.2844 679.32 Q51.1149 682.631 48.9187 687.405 Q46.6907 692.147 46.6907 697.749 Q46.6907 701.664 47.7411 705.261 Q48.7596 708.857 50.7966 711.913 Q54.0431 716.91 59.3266 719.743 Q64.5784 722.544 70.7213 722.544 Q75.782 722.544 80.2062 720.729 Q84.6303 718.883 88.0042 715.414 Q91.3143 712.072 93.0331 707.68 Q94.7836 703.287 94.7836 698.29 Q94.7836 694.184 93.3832 690.238 Q92.0146 686.259 89.4364 682.949 L92.9694 680.084 Q96.0568 684.063 97.68 688.773 Q99.3351 693.452 99.3351 698.29 Q99.3351 704.178 97.2344 709.398 Q95.1656 714.618 91.187 718.692 Q87.2084 722.766 81.9886 724.899 Q76.7369 727.031 70.7213 727.031 Q64.9285 727.031 59.6768 724.867 Q54.4251 722.703 50.4465 718.692 Q46.4043 714.586 44.2718 709.207 Q42.1074 703.828 42.1074 697.813 Q42.1074 691.065 44.8765 685.304 Q47.6456 679.511 52.7381 675.596 Q55.8573 673.209 59.5176 671.968 Q63.1779 670.695 67.0928 670.695 Q75.4637 670.695 80.3017 675.756 Q85.1396 680.816 85.3306 689.728 L80.429 689.728 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip100)\" d=\"M 0 0 M82.5933 658.186 L82.5933 635.747 L88.0042 635.747 L88.0042 665.921 L82.5933 665.921 Q78.8057 662.26 72.44 655.958 Q66.0425 649.624 64.1964 648.001 Q60.7271 644.914 58.34 643.704 Q55.921 642.463 53.5975 642.463 Q49.8099 642.463 47.4228 645.137 Q45.0356 647.778 45.0356 652.043 Q45.0356 655.067 46.086 658.441 Q47.1363 661.783 49.2688 665.602 L42.7758 665.602 Q41.2162 661.719 40.4205 658.345 Q39.6248 654.972 39.6248 652.171 Q39.6248 644.786 43.3169 640.394 Q47.009 636.002 53.1837 636.002 Q56.112 636.002 58.7537 637.116 Q61.3637 638.198 64.9285 641.094 Q65.8515 641.89 70.2757 646.155 Q74.668 650.42 82.5933 658.186 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip100)\" d=\"M 0 0 M44.7174 615.027 Q44.7174 619.992 49.6189 622.506 Q54.4887 624.989 64.2919 624.989 Q74.0633 624.989 78.9649 622.506 Q83.8346 619.992 83.8346 615.027 Q83.8346 610.03 78.9649 607.547 Q74.0633 605.033 64.2919 605.033 Q54.4887 605.033 49.6189 607.547 Q44.7174 610.03 44.7174 615.027 M39.6248 615.027 Q39.6248 607.038 45.9587 602.836 Q52.2607 598.603 64.2919 598.603 Q76.2913 598.603 82.6251 602.836 Q88.9272 607.038 88.9272 615.027 Q88.9272 623.016 82.6251 627.249 Q76.2913 631.45 64.2919 631.45 Q52.2607 631.45 45.9587 627.249 Q39.6248 623.016 39.6248 615.027 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip100)\" d=\"M 0 0 M322.338 44.2197 Q324.971 45.1109 327.442 48.0275 Q329.953 50.9442 332.465 56.0483 L340.769 72.576 L331.979 72.576 L324.242 57.061 Q321.244 50.9847 318.408 48.9997 Q315.613 47.0148 310.752 47.0148 L301.84 47.0148 L301.84 72.576 L293.657 72.576 L293.657 12.096 L312.129 12.096 Q322.5 12.096 327.604 16.4305 Q332.708 20.7649 332.708 29.5149 Q332.708 35.2267 330.034 38.994 Q327.401 42.7613 322.338 44.2197 M301.84 18.8205 L301.84 40.2903 L312.129 40.2903 Q318.044 40.2903 321.041 37.5762 Q324.08 34.8216 324.08 29.5149 Q324.08 24.2082 321.041 21.5346 Q318.044 18.8205 312.129 18.8205 L301.84 18.8205 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip100)\" d=\"M 0 0 M383.668 48.0275 L383.668 51.6733 L349.398 51.6733 Q349.884 59.3701 354.016 63.421 Q358.188 67.4314 365.601 67.4314 Q369.895 67.4314 373.906 66.3781 Q377.957 65.3249 381.926 63.2184 L381.926 70.267 Q377.916 71.9684 373.703 72.8596 Q369.49 73.7508 365.156 73.7508 Q354.299 73.7508 347.939 67.4314 Q341.62 61.1119 341.62 50.3365 Q341.62 39.1965 347.615 32.6746 Q353.651 26.1121 363.859 26.1121 Q373.014 26.1121 378.321 32.0264 Q383.668 37.9003 383.668 48.0275 M376.215 45.84 Q376.134 39.7232 372.771 36.0774 Q369.45 32.4315 363.94 32.4315 Q357.702 32.4315 353.935 35.9558 Q350.208 39.4801 349.641 45.8805 L376.215 45.84 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip100)\" d=\"M 0 0 M424.137 28.9478 L424.137 35.9153 Q420.977 34.1734 417.777 33.3227 Q414.617 32.4315 411.377 32.4315 Q404.125 32.4315 400.115 37.0496 Q396.105 41.6271 396.105 49.9314 Q396.105 58.2358 400.115 62.8538 Q404.125 67.4314 411.377 67.4314 Q414.617 67.4314 417.777 66.5807 Q420.977 65.6895 424.137 63.9476 L424.137 70.8341 Q421.018 72.2924 417.655 73.0216 Q414.334 73.7508 410.566 73.7508 Q400.318 73.7508 394.282 67.3098 Q388.246 60.8689 388.246 49.9314 Q388.246 38.832 394.322 32.472 Q400.439 26.1121 411.052 26.1121 Q414.496 26.1121 417.777 26.8413 Q421.058 27.5299 424.137 28.9478 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip100)\" d=\"M 0 0 M452.574 49.7694 Q443.541 49.7694 440.057 51.8354 Q436.573 53.9013 436.573 58.8839 Q436.573 62.8538 439.166 65.2034 Q441.799 67.5124 446.295 67.5124 Q452.493 67.5124 456.22 63.1374 Q459.987 58.7219 459.987 51.4303 L459.987 49.7694 L452.574 49.7694 M467.441 46.6907 L467.441 72.576 L459.987 72.576 L459.987 65.6895 Q457.435 69.8214 453.627 71.8063 Q449.82 73.7508 444.31 73.7508 Q437.343 73.7508 433.211 69.8619 Q429.119 65.9325 429.119 59.3701 Q429.119 51.7138 434.224 47.825 Q439.368 43.9361 449.536 43.9361 L459.987 43.9361 L459.987 43.2069 Q459.987 38.0623 456.585 35.2672 Q453.222 32.4315 447.106 32.4315 Q443.217 32.4315 439.53 33.3632 Q435.844 34.295 432.441 36.1584 L432.441 29.2718 Q436.533 27.692 440.381 26.9223 Q444.229 26.1121 447.875 26.1121 Q457.719 26.1121 462.58 31.2163 Q467.441 36.3204 467.441 46.6907 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip100)\" d=\"M 0 0 M475.259 9.54393 L482.713 9.54393 L482.713 72.576 L475.259 72.576 L475.259 9.54393 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip100)\" d=\"M 0 0 M490.531 9.54393 L497.985 9.54393 L497.985 72.576 L490.531 72.576 L490.531 9.54393 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip100)\" d=\"M 0 0 M534.646 65.6895 L548.014 65.6895 L548.014 19.5497 L533.471 22.4663 L533.471 15.0127 L547.933 12.096 L556.115 12.096 L556.115 65.6895 L569.483 65.6895 L569.483 72.576 L534.646 72.576 L534.646 65.6895 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip100)\" d=\"M 0 0 M600.351 50.8226 Q600.351 56.6154 603.227 59.9372 Q606.104 63.2184 611.127 63.2184 Q616.109 63.2184 618.945 59.8967 Q621.821 56.5749 621.821 50.8226 Q621.821 45.1514 618.904 41.8296 Q615.988 38.4674 611.046 38.4674 Q606.144 38.4674 603.227 41.7891 Q600.351 45.1109 600.351 50.8226 M622.429 62.9348 Q619.998 66.054 616.838 67.5529 Q613.719 69.0112 609.547 69.0112 Q602.579 69.0112 598.204 63.9881 Q593.87 58.9245 593.87 50.8226 Q593.87 42.7208 598.245 37.6572 Q602.62 32.5936 609.547 32.5936 Q613.719 32.5936 616.879 34.1329 Q620.039 35.6318 622.429 38.7104 L622.429 33.4038 L628.221 33.4038 L628.221 63.2184 Q634.136 62.3272 637.458 57.8307 Q640.82 53.2937 640.82 46.1236 Q640.82 41.7891 639.523 37.9813 Q638.268 34.1734 635.675 30.9327 Q631.462 25.626 625.386 22.8309 Q619.35 19.9953 612.22 19.9953 Q607.238 19.9953 602.66 21.3321 Q598.083 22.6284 594.194 25.2209 Q587.834 29.3529 584.229 36.0774 Q580.664 42.7613 580.664 50.5796 Q580.664 57.0205 582.973 62.6513 Q585.322 68.282 589.738 72.576 Q593.991 76.7889 599.582 78.9764 Q605.172 81.2044 611.532 81.2044 Q616.757 81.2044 621.781 79.422 Q626.844 77.6801 631.057 74.3989 L634.703 78.8954 Q629.639 82.8248 623.644 84.8907 Q617.689 86.9972 611.532 86.9972 Q604.038 86.9972 597.394 84.3236 Q590.751 81.6905 585.565 76.6269 Q580.38 71.5633 577.666 64.9198 Q574.952 58.2358 574.952 50.5796 Q574.952 43.2069 577.707 36.523 Q580.461 29.839 585.565 24.7753 Q590.791 19.6307 597.637 16.9166 Q604.483 14.162 612.139 14.162 Q620.727 14.162 628.059 17.6862 Q635.432 21.2105 640.415 27.692 Q643.453 31.6619 645.033 36.3204 Q646.653 40.9789 646.653 45.9616 Q646.653 56.6154 640.212 62.7728 Q633.771 68.9302 622.429 69.1732 L622.429 62.9348 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip100)\" d=\"M 0 0 M662.573 65.6895 L691.132 65.6895 L691.132 72.576 L652.729 72.576 L652.729 65.6895 Q657.388 60.8689 665.409 52.7671 Q673.47 44.6248 675.536 42.2752 Q679.465 37.8598 681.005 34.8216 Q682.585 31.7429 682.585 28.7857 Q682.585 23.9651 679.182 20.927 Q675.82 17.8888 670.391 17.8888 Q666.543 17.8888 662.249 19.2256 Q657.996 20.5624 653.135 23.2765 L653.135 15.0127 Q658.077 13.0277 662.371 12.015 Q666.665 11.0023 670.229 11.0023 Q679.627 11.0023 685.218 15.7013 Q690.808 20.4004 690.808 28.2591 Q690.808 31.9859 689.39 35.3482 Q688.013 38.6699 684.326 43.2069 Q683.314 44.3817 677.886 50.0125 Q672.457 55.6027 662.573 65.6895 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip100)\" d=\"M 0 0 M717.503 17.4837 Q711.184 17.4837 707.984 23.7221 Q704.824 29.92 704.824 42.3968 Q704.824 54.833 707.984 61.0714 Q711.184 67.2693 717.503 67.2693 Q723.863 67.2693 727.023 61.0714 Q730.223 54.833 730.223 42.3968 Q730.223 29.92 727.023 23.7221 Q723.863 17.4837 717.503 17.4837 M717.503 11.0023 Q727.671 11.0023 733.018 19.0636 Q738.406 27.0843 738.406 42.3968 Q738.406 57.6687 733.018 65.73 Q727.671 73.7508 717.503 73.7508 Q707.336 73.7508 701.948 65.73 Q696.601 57.6687 696.601 42.3968 Q696.601 27.0843 701.948 19.0636 Q707.336 11.0023 717.503 11.0023 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip100)\" d=\"M 0 0 M790.177 32.4315 Q784.181 32.4315 780.697 37.1306 Q777.214 41.7891 777.214 49.9314 Q777.214 58.0738 780.657 62.7728 Q784.141 67.4314 790.177 67.4314 Q796.131 67.4314 799.615 62.7323 Q803.099 58.0333 803.099 49.9314 Q803.099 41.8701 799.615 37.1711 Q796.131 32.4315 790.177 32.4315 M790.177 26.1121 Q799.899 26.1121 805.449 32.4315 Q810.998 38.7509 810.998 49.9314 Q810.998 61.0714 805.449 67.4314 Q799.899 73.7508 790.177 73.7508 Q780.414 73.7508 774.864 67.4314 Q769.355 61.0714 769.355 49.9314 Q769.355 38.7509 774.864 32.4315 Q780.414 26.1121 790.177 26.1121 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip100)\" d=\"M 0 0 M856.53 45.1919 L856.53 72.576 L849.077 72.576 L849.077 45.4349 Q849.077 38.994 846.565 35.7938 Q844.054 32.5936 839.03 32.5936 Q832.995 32.5936 829.511 36.4419 Q826.027 40.2903 826.027 46.9338 L826.027 72.576 L818.533 72.576 L818.533 27.2059 L826.027 27.2059 L826.027 34.2544 Q828.701 30.163 832.306 28.1376 Q835.952 26.1121 840.691 26.1121 Q848.51 26.1121 852.52 30.9732 Q856.53 35.7938 856.53 45.1919 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip100)\" d=\"M 0 0 M893.191 65.6895 L906.559 65.6895 L906.559 19.5497 L892.016 22.4663 L892.016 15.0127 L906.478 12.096 L914.661 12.096 L914.661 65.6895 L928.029 65.6895 L928.029 72.576 L893.191 72.576 L893.191 65.6895 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip100)\" d=\"M 0 0 M954.4 17.4837 Q948.081 17.4837 944.881 23.7221 Q941.721 29.92 941.721 42.3968 Q941.721 54.833 944.881 61.0714 Q948.081 67.2693 954.4 67.2693 Q960.76 67.2693 963.92 61.0714 Q967.12 54.833 967.12 42.3968 Q967.12 29.92 963.92 23.7221 Q960.76 17.4837 954.4 17.4837 M954.4 11.0023 Q964.568 11.0023 969.915 19.0636 Q975.303 27.0843 975.303 42.3968 Q975.303 57.6687 969.915 65.73 Q964.568 73.7508 954.4 73.7508 Q944.232 73.7508 938.845 65.73 Q933.498 57.6687 933.498 42.3968 Q933.498 27.0843 938.845 19.0636 Q944.232 11.0023 954.4 11.0023 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip100)\" d=\"M 0 0 M1001.67 17.4837 Q995.355 17.4837 992.155 23.7221 Q988.995 29.92 988.995 42.3968 Q988.995 54.833 992.155 61.0714 Q995.355 67.2693 1001.67 67.2693 Q1008.03 67.2693 1011.19 61.0714 Q1014.39 54.833 1014.39 42.3968 Q1014.39 29.92 1011.19 23.7221 Q1008.03 17.4837 1001.67 17.4837 M1001.67 11.0023 Q1011.84 11.0023 1017.19 19.0636 Q1022.58 27.0843 1022.58 42.3968 Q1022.58 57.6687 1017.19 65.73 Q1011.84 73.7508 1001.67 73.7508 Q991.507 73.7508 986.119 65.73 Q980.772 57.6687 980.772 42.3968 Q980.772 27.0843 986.119 19.0636 Q991.507 11.0023 1001.67 11.0023 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip100)\" d=\"M 0 0 M1048.95 17.4837 Q1042.63 17.4837 1039.43 23.7221 Q1036.27 29.92 1036.27 42.3968 Q1036.27 54.833 1039.43 61.0714 Q1042.63 67.2693 1048.95 67.2693 Q1055.31 67.2693 1058.47 61.0714 Q1061.67 54.833 1061.67 42.3968 Q1061.67 29.92 1058.47 23.7221 Q1055.31 17.4837 1048.95 17.4837 M1048.95 11.0023 Q1059.12 11.0023 1064.46 19.0636 Q1069.85 27.0843 1069.85 42.3968 Q1069.85 57.6687 1064.46 65.73 Q1059.12 73.7508 1048.95 73.7508 Q1038.78 73.7508 1033.39 65.73 Q1028.05 57.6687 1028.05 42.3968 Q1028.05 27.0843 1033.39 19.0636 Q1038.78 11.0023 1048.95 11.0023 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip100)\" d=\"M 0 0 M1115.38 27.2059 L1098.98 49.2833 L1116.23 72.576 L1107.44 72.576 L1094.24 54.752 L1081.03 72.576 L1072.24 72.576 L1089.86 48.8377 L1073.74 27.2059 L1082.53 27.2059 L1094.56 43.369 L1106.59 27.2059 L1115.38 27.2059 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip100)\" d=\"M 0 0 M1126.52 65.6895 L1139.89 65.6895 L1139.89 19.5497 L1125.35 22.4663 L1125.35 15.0127 L1139.81 12.096 L1147.99 12.096 L1147.99 65.6895 L1161.36 65.6895 L1161.36 72.576 L1126.52 72.576 L1126.52 65.6895 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip100)\" d=\"M 0 0 M1188.75 39.075 Q1183.24 39.075 1180 42.8424 Q1176.79 46.6097 1176.79 53.1722 Q1176.79 59.6941 1180 63.502 Q1183.24 67.2693 1188.75 67.2693 Q1194.25 67.2693 1197.45 63.502 Q1200.7 59.6941 1200.7 53.1722 Q1200.7 46.6097 1197.45 42.8424 Q1194.25 39.075 1188.75 39.075 M1204.99 13.4328 L1204.99 20.8865 Q1201.91 19.4281 1198.75 18.6585 Q1195.63 17.8888 1192.55 17.8888 Q1184.45 17.8888 1180.16 23.3575 Q1175.9 28.8262 1175.3 39.8852 Q1177.69 36.3609 1181.29 34.4975 Q1184.9 32.5936 1189.23 32.5936 Q1198.35 32.5936 1203.61 38.1433 Q1208.92 43.6525 1208.92 53.1722 Q1208.92 62.4892 1203.41 68.12 Q1197.9 73.7508 1188.75 73.7508 Q1178.25 73.7508 1172.7 65.73 Q1167.15 57.6687 1167.15 42.3968 Q1167.15 28.0566 1173.96 19.5497 Q1180.76 11.0023 1192.23 11.0023 Q1195.31 11.0023 1198.43 11.6099 Q1201.59 12.2175 1204.99 13.4328 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip100)\" d=\"M 0 0 M1263.73 49.7694 Q1254.69 49.7694 1251.21 51.8354 Q1247.73 53.9013 1247.73 58.8839 Q1247.73 62.8538 1250.32 65.2034 Q1252.95 67.5124 1257.45 67.5124 Q1263.65 67.5124 1267.37 63.1374 Q1271.14 58.7219 1271.14 51.4303 L1271.14 49.7694 L1263.73 49.7694 M1278.59 46.6907 L1278.59 72.576 L1271.14 72.576 L1271.14 65.6895 Q1268.59 69.8214 1264.78 71.8063 Q1260.97 73.7508 1255.46 73.7508 Q1248.5 73.7508 1244.36 69.8619 Q1240.27 65.9325 1240.27 59.3701 Q1240.27 51.7138 1245.38 47.825 Q1250.52 43.9361 1260.69 43.9361 L1271.14 43.9361 L1271.14 43.2069 Q1271.14 38.0623 1267.74 35.2672 Q1264.38 32.4315 1258.26 32.4315 Q1254.37 32.4315 1250.68 33.3632 Q1247 34.295 1243.59 36.1584 L1243.59 29.2718 Q1247.69 27.692 1251.53 26.9223 Q1255.38 26.1121 1259.03 26.1121 Q1268.87 26.1121 1273.73 31.2163 Q1278.59 36.3204 1278.59 46.6907 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip100)\" d=\"M 0 0 M1312.7 34.1734 Q1311.45 33.4443 1309.95 33.1202 Q1308.49 32.7556 1306.71 32.7556 Q1300.39 32.7556 1296.99 36.8875 Q1293.62 40.9789 1293.62 48.6757 L1293.62 72.576 L1286.13 72.576 L1286.13 27.2059 L1293.62 27.2059 L1293.62 34.2544 Q1295.97 30.1225 1299.74 28.1376 Q1303.51 26.1121 1308.89 26.1121 Q1309.66 26.1121 1310.6 26.2337 Q1311.53 26.3147 1312.66 26.5172 L1312.7 34.1734 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip100)\" d=\"M 0 0 M1327.89 14.324 L1327.89 27.2059 L1343.25 27.2059 L1343.25 32.9987 L1327.89 32.9987 L1327.89 57.6282 Q1327.89 63.1779 1329.39 64.7578 Q1330.93 66.3376 1335.59 66.3376 L1343.25 66.3376 L1343.25 72.576 L1335.59 72.576 Q1326.96 72.576 1323.68 69.3758 Q1320.4 66.1351 1320.4 57.6282 L1320.4 32.9987 L1314.93 32.9987 L1314.93 27.2059 L1320.4 27.2059 L1320.4 14.324 L1327.89 14.324 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip100)\" d=\"M 0 0 M1351.06 27.2059 L1358.52 27.2059 L1358.52 72.576 L1351.06 72.576 L1351.06 27.2059 M1351.06 9.54393 L1358.52 9.54393 L1358.52 18.9825 L1351.06 18.9825 L1351.06 9.54393 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip100)\" d=\"M 0 0 M1389.31 9.54393 L1389.31 15.7418 L1382.18 15.7418 Q1378.17 15.7418 1376.59 17.3622 Q1375.05 18.9825 1375.05 23.1955 L1375.05 27.2059 L1387.32 27.2059 L1387.32 32.9987 L1375.05 32.9987 L1375.05 72.576 L1367.55 72.576 L1367.55 32.9987 L1360.42 32.9987 L1360.42 27.2059 L1367.55 27.2059 L1367.55 24.0462 Q1367.55 16.471 1371.08 13.0277 Q1374.6 9.54393 1382.26 9.54393 L1389.31 9.54393 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip100)\" d=\"M 0 0 M1397.12 27.2059 L1404.58 27.2059 L1404.58 72.576 L1397.12 72.576 L1397.12 27.2059 M1397.12 9.54393 L1404.58 9.54393 L1404.58 18.9825 L1397.12 18.9825 L1397.12 9.54393 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip100)\" d=\"M 0 0 M1445.05 28.9478 L1445.05 35.9153 Q1441.89 34.1734 1438.69 33.3227 Q1435.53 32.4315 1432.29 32.4315 Q1425.03 32.4315 1421.02 37.0496 Q1417.01 41.6271 1417.01 49.9314 Q1417.01 58.2358 1421.02 62.8538 Q1425.03 67.4314 1432.29 67.4314 Q1435.53 67.4314 1438.69 66.5807 Q1441.89 65.6895 1445.05 63.9476 L1445.05 70.8341 Q1441.93 72.2924 1438.56 73.0216 Q1435.24 73.7508 1431.48 73.7508 Q1421.23 73.7508 1415.19 67.3098 Q1409.15 60.8689 1409.15 49.9314 Q1409.15 38.832 1415.23 32.472 Q1421.35 26.1121 1431.96 26.1121 Q1435.4 26.1121 1438.69 26.8413 Q1441.97 27.5299 1445.05 28.9478 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip100)\" d=\"M 0 0 M1473.48 49.7694 Q1464.45 49.7694 1460.97 51.8354 Q1457.48 53.9013 1457.48 58.8839 Q1457.48 62.8538 1460.07 65.2034 Q1462.71 67.5124 1467.2 67.5124 Q1473.4 67.5124 1477.13 63.1374 Q1480.9 58.7219 1480.9 51.4303 L1480.9 49.7694 L1473.48 49.7694 M1488.35 46.6907 L1488.35 72.576 L1480.9 72.576 L1480.9 65.6895 Q1478.34 69.8214 1474.54 71.8063 Q1470.73 73.7508 1465.22 73.7508 Q1458.25 73.7508 1454.12 69.8619 Q1450.03 65.9325 1450.03 59.3701 Q1450.03 51.7138 1455.13 47.825 Q1460.28 43.9361 1470.44 43.9361 L1480.9 43.9361 L1480.9 43.2069 Q1480.9 38.0623 1477.49 35.2672 Q1474.13 32.4315 1468.01 32.4315 Q1464.13 32.4315 1460.44 33.3632 Q1456.75 34.295 1453.35 36.1584 L1453.35 29.2718 Q1457.44 27.692 1461.29 26.9223 Q1465.14 26.1121 1468.78 26.1121 Q1478.63 26.1121 1483.49 31.2163 Q1488.35 36.3204 1488.35 46.6907 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip100)\" d=\"M 0 0 M1496.17 9.54393 L1503.62 9.54393 L1503.62 72.576 L1496.17 72.576 L1496.17 9.54393 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip100)\" d=\"M 0 0 M1567.67 34.0924 L1567.67 9.54393 L1575.12 9.54393 L1575.12 72.576 L1567.67 72.576 L1567.67 65.7705 Q1565.32 69.8214 1561.71 71.8063 Q1558.15 73.7508 1553.12 73.7508 Q1544.9 73.7508 1539.72 67.1883 Q1534.57 60.6258 1534.57 49.9314 Q1534.57 39.2371 1539.72 32.6746 Q1544.9 26.1121 1553.12 26.1121 Q1558.15 26.1121 1561.71 28.0971 Q1565.32 30.0415 1567.67 34.0924 M1542.27 49.9314 Q1542.27 58.1548 1545.63 62.8538 Q1549.03 67.5124 1554.95 67.5124 Q1560.86 67.5124 1564.26 62.8538 Q1567.67 58.1548 1567.67 49.9314 Q1567.67 41.7081 1564.26 37.0496 Q1560.86 32.3505 1554.95 32.3505 Q1549.03 32.3505 1545.63 37.0496 Q1542.27 41.7081 1542.27 49.9314 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip100)\" d=\"M 0 0 M1603.56 49.7694 Q1594.52 49.7694 1591.04 51.8354 Q1587.56 53.9013 1587.56 58.8839 Q1587.56 62.8538 1590.15 65.2034 Q1592.78 67.5124 1597.28 67.5124 Q1603.48 67.5124 1607.2 63.1374 Q1610.97 58.7219 1610.97 51.4303 L1610.97 49.7694 L1603.56 49.7694 M1618.42 46.6907 L1618.42 72.576 L1610.97 72.576 L1610.97 65.6895 Q1608.42 69.8214 1604.61 71.8063 Q1600.8 73.7508 1595.29 73.7508 Q1588.33 73.7508 1584.19 69.8619 Q1580.1 65.9325 1580.1 59.3701 Q1580.1 51.7138 1585.21 47.825 Q1590.35 43.9361 1600.52 43.9361 L1610.97 43.9361 L1610.97 43.2069 Q1610.97 38.0623 1607.57 35.2672 Q1604.21 32.4315 1598.09 32.4315 Q1594.2 32.4315 1590.51 33.3632 Q1586.83 34.295 1583.42 36.1584 L1583.42 29.2718 Q1587.52 27.692 1591.36 26.9223 Q1595.21 26.1121 1598.86 26.1121 Q1608.7 26.1121 1613.56 31.2163 Q1618.42 36.3204 1618.42 46.6907 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip100)\" d=\"M 0 0 M1633.62 14.324 L1633.62 27.2059 L1648.97 27.2059 L1648.97 32.9987 L1633.62 32.9987 L1633.62 57.6282 Q1633.62 63.1779 1635.11 64.7578 Q1636.65 66.3376 1641.31 66.3376 L1648.97 66.3376 L1648.97 72.576 L1641.31 72.576 Q1632.68 72.576 1629.4 69.3758 Q1626.12 66.1351 1626.12 57.6282 L1626.12 32.9987 L1620.65 32.9987 L1620.65 27.2059 L1626.12 27.2059 L1626.12 14.324 L1633.62 14.324 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip100)\" d=\"M 0 0 M1677.41 49.7694 Q1668.37 49.7694 1664.89 51.8354 Q1661.4 53.9013 1661.4 58.8839 Q1661.4 62.8538 1664 65.2034 Q1666.63 67.5124 1671.13 67.5124 Q1677.32 67.5124 1681.05 63.1374 Q1684.82 58.7219 1684.82 51.4303 L1684.82 49.7694 L1677.41 49.7694 M1692.27 46.6907 L1692.27 72.576 L1684.82 72.576 L1684.82 65.6895 Q1682.27 69.8214 1678.46 71.8063 Q1674.65 73.7508 1669.14 73.7508 Q1662.17 73.7508 1658.04 69.8619 Q1653.95 65.9325 1653.95 59.3701 Q1653.95 51.7138 1659.06 47.825 Q1664.2 43.9361 1674.37 43.9361 L1684.82 43.9361 L1684.82 43.2069 Q1684.82 38.0623 1681.42 35.2672 Q1678.05 32.4315 1671.94 32.4315 Q1668.05 32.4315 1664.36 33.3632 Q1660.68 34.295 1657.27 36.1584 L1657.27 29.2718 Q1661.36 27.692 1665.21 26.9223 Q1669.06 26.1121 1672.71 26.1121 Q1682.55 26.1121 1687.41 31.2163 Q1692.27 36.3204 1692.27 46.6907 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip100)\" d=\"M 0 0 M1701.99 62.2867 L1710.54 62.2867 L1710.54 69.2543 L1703.9 82.2172 L1698.67 82.2172 L1701.99 69.2543 L1701.99 62.2867 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip100)\" d=\"M 0 0 M1763.28 43.8551 Q1757.45 43.8551 1754.09 46.9743 Q1750.77 50.0935 1750.77 55.5622 Q1750.77 61.0309 1754.09 64.1501 Q1757.45 67.2693 1763.28 67.2693 Q1769.12 67.2693 1772.48 64.1501 Q1775.84 60.9904 1775.84 55.5622 Q1775.84 50.0935 1772.48 46.9743 Q1769.16 43.8551 1763.28 43.8551 M1755.1 40.3713 Q1749.84 39.075 1746.88 35.4697 Q1743.96 31.8644 1743.96 26.6793 Q1743.96 19.4281 1749.11 15.2152 Q1754.29 11.0023 1763.28 11.0023 Q1772.32 11.0023 1777.46 15.2152 Q1782.61 19.4281 1782.61 26.6793 Q1782.61 31.8644 1779.65 35.4697 Q1776.73 39.075 1771.51 40.3713 Q1777.42 41.7486 1780.7 45.759 Q1784.03 49.7694 1784.03 55.5622 Q1784.03 64.3527 1778.64 69.0517 Q1773.29 73.7508 1763.28 73.7508 Q1753.28 73.7508 1747.89 69.0517 Q1742.54 64.3527 1742.54 55.5622 Q1742.54 49.7694 1745.87 45.759 Q1749.19 41.7486 1755.1 40.3713 M1752.1 27.4489 Q1752.1 32.148 1755.02 34.7811 Q1757.98 37.4142 1763.28 37.4142 Q1768.55 37.4142 1771.51 34.7811 Q1774.51 32.148 1774.51 27.4489 Q1774.51 22.7499 1771.51 20.1168 Q1768.55 17.4837 1763.28 17.4837 Q1757.98 17.4837 1755.02 20.1168 Q1752.1 22.7499 1752.1 27.4489 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip100)\" d=\"M 0 0 M1829.56 27.2059 L1813.15 49.2833 L1830.41 72.576 L1821.62 72.576 L1808.41 54.752 L1795.21 72.576 L1786.42 72.576 L1804.04 48.8377 L1787.91 27.2059 L1796.7 27.2059 L1808.74 43.369 L1820.77 27.2059 L1829.56 27.2059 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip100)\" d=\"M 0 0 M1856.78 43.8551 Q1850.95 43.8551 1847.58 46.9743 Q1844.26 50.0935 1844.26 55.5622 Q1844.26 61.0309 1847.58 64.1501 Q1850.95 67.2693 1856.78 67.2693 Q1862.61 67.2693 1865.98 64.1501 Q1869.34 60.9904 1869.34 55.5622 Q1869.34 50.0935 1865.98 46.9743 Q1862.65 43.8551 1856.78 43.8551 M1848.6 40.3713 Q1843.33 39.075 1840.37 35.4697 Q1837.46 31.8644 1837.46 26.6793 Q1837.46 19.4281 1842.6 15.2152 Q1847.79 11.0023 1856.78 11.0023 Q1865.81 11.0023 1870.96 15.2152 Q1876.1 19.4281 1876.1 26.6793 Q1876.1 31.8644 1873.15 35.4697 Q1870.23 39.075 1865 40.3713 Q1870.92 41.7486 1874.2 45.759 Q1877.52 49.7694 1877.52 55.5622 Q1877.52 64.3527 1872.13 69.0517 Q1866.79 73.7508 1856.78 73.7508 Q1846.77 73.7508 1841.39 69.0517 Q1836.04 64.3527 1836.04 55.5622 Q1836.04 49.7694 1839.36 45.759 Q1842.68 41.7486 1848.6 40.3713 M1845.6 27.4489 Q1845.6 32.148 1848.52 34.7811 Q1851.47 37.4142 1856.78 37.4142 Q1862.05 37.4142 1865 34.7811 Q1868 32.148 1868 27.4489 Q1868 22.7499 1865 20.1168 Q1862.05 17.4837 1856.78 17.4837 Q1851.47 17.4837 1848.52 20.1168 Q1845.6 22.7499 1845.6 27.4489 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip100)\" d=\"M 0 0 M1944.36 28.9478 L1944.36 35.9153 Q1941.2 34.1734 1938 33.3227 Q1934.84 32.4315 1931.6 32.4315 Q1924.35 32.4315 1920.34 37.0496 Q1916.33 41.6271 1916.33 49.9314 Q1916.33 58.2358 1920.34 62.8538 Q1924.35 67.4314 1931.6 67.4314 Q1934.84 67.4314 1938 66.5807 Q1941.2 65.6895 1944.36 63.9476 L1944.36 70.8341 Q1941.24 72.2924 1937.88 73.0216 Q1934.56 73.7508 1930.79 73.7508 Q1920.54 73.7508 1914.51 67.3098 Q1908.47 60.8689 1908.47 49.9314 Q1908.47 38.832 1914.55 32.472 Q1920.66 26.1121 1931.28 26.1121 Q1934.72 26.1121 1938 26.8413 Q1941.28 27.5299 1944.36 28.9478 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip100)\" d=\"M 0 0 M1969.76 32.4315 Q1963.76 32.4315 1960.28 37.1306 Q1956.8 41.7891 1956.8 49.9314 Q1956.8 58.0738 1960.24 62.7728 Q1963.72 67.4314 1969.76 67.4314 Q1975.71 67.4314 1979.2 62.7323 Q1982.68 58.0333 1982.68 49.9314 Q1982.68 41.8701 1979.2 37.1711 Q1975.71 32.4315 1969.76 32.4315 M1969.76 26.1121 Q1979.48 26.1121 1985.03 32.4315 Q1990.58 38.7509 1990.58 49.9314 Q1990.58 61.0714 1985.03 67.4314 Q1979.48 73.7508 1969.76 73.7508 Q1960 73.7508 1954.45 67.4314 Q1948.94 61.0714 1948.94 49.9314 Q1948.94 38.7509 1954.45 32.4315 Q1960 26.1121 1969.76 26.1121 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip100)\" d=\"M 0 0 M2028.25 34.0924 L2028.25 9.54393 L2035.71 9.54393 L2035.71 72.576 L2028.25 72.576 L2028.25 65.7705 Q2025.9 69.8214 2022.3 71.8063 Q2018.73 73.7508 2013.71 73.7508 Q2005.49 73.7508 2000.3 67.1883 Q1995.16 60.6258 1995.16 49.9314 Q1995.16 39.2371 2000.3 32.6746 Q2005.49 26.1121 2013.71 26.1121 Q2018.73 26.1121 2022.3 28.0971 Q2025.9 30.0415 2028.25 34.0924 M2002.86 49.9314 Q2002.86 58.1548 2006.22 62.8538 Q2009.62 67.5124 2015.53 67.5124 Q2021.45 67.5124 2024.85 62.8538 Q2028.25 58.1548 2028.25 49.9314 Q2028.25 41.7081 2024.85 37.0496 Q2021.45 32.3505 2015.53 32.3505 Q2009.62 32.3505 2006.22 37.0496 Q2002.86 41.7081 2002.86 49.9314 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip100)\" d=\"M 0 0 M2082.33 48.0275 L2082.33 51.6733 L2048.06 51.6733 Q2048.55 59.3701 2052.68 63.421 Q2056.85 67.4314 2064.27 67.4314 Q2068.56 67.4314 2072.57 66.3781 Q2076.62 65.3249 2080.59 63.2184 L2080.59 70.267 Q2076.58 71.9684 2072.37 72.8596 Q2068.16 73.7508 2063.82 73.7508 Q2052.96 73.7508 2046.61 67.4314 Q2040.29 61.1119 2040.29 50.3365 Q2040.29 39.1965 2046.28 32.6746 Q2052.32 26.1121 2062.53 26.1121 Q2071.68 26.1121 2076.99 32.0264 Q2082.33 37.9003 2082.33 48.0275 M2074.88 45.84 Q2074.8 39.7232 2071.44 36.0774 Q2068.12 32.4315 2062.61 32.4315 Q2056.37 32.4315 2052.6 35.9558 Q2048.87 39.4801 2048.31 45.8805 L2074.88 45.84 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip100)\" d=\"M 0 0 M2122.72 49.9314 Q2122.72 41.7081 2119.32 37.0496 Q2115.96 32.3505 2110.04 32.3505 Q2104.13 32.3505 2100.73 37.0496 Q2097.36 41.7081 2097.36 49.9314 Q2097.36 58.1548 2100.73 62.8538 Q2104.13 67.5124 2110.04 67.5124 Q2115.96 67.5124 2119.32 62.8538 Q2122.72 58.1548 2122.72 49.9314 M2097.36 34.0924 Q2099.71 30.0415 2103.28 28.0971 Q2106.88 26.1121 2111.87 26.1121 Q2120.13 26.1121 2125.27 32.6746 Q2130.46 39.2371 2130.46 49.9314 Q2130.46 60.6258 2125.27 67.1883 Q2120.13 73.7508 2111.87 73.7508 Q2106.88 73.7508 2103.28 71.8063 Q2099.71 69.8214 2097.36 65.7705 L2097.36 72.576 L2089.87 72.576 L2089.87 9.54393 L2097.36 9.54393 L2097.36 34.0924 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip100)\" d=\"M 0 0 M2155.86 32.4315 Q2149.86 32.4315 2146.38 37.1306 Q2142.9 41.7891 2142.9 49.9314 Q2142.9 58.0738 2146.34 62.7728 Q2149.82 67.4314 2155.86 67.4314 Q2161.81 67.4314 2165.3 62.7323 Q2168.78 58.0333 2168.78 49.9314 Q2168.78 41.8701 2165.3 37.1711 Q2161.81 32.4315 2155.86 32.4315 M2155.86 26.1121 Q2165.58 26.1121 2171.13 32.4315 Q2176.68 38.7509 2176.68 49.9314 Q2176.68 61.0714 2171.13 67.4314 Q2165.58 73.7508 2155.86 73.7508 Q2146.1 73.7508 2140.55 67.4314 Q2135.04 61.0714 2135.04 49.9314 Q2135.04 38.7509 2140.55 32.4315 Q2146.1 26.1121 2155.86 26.1121 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip100)\" d=\"M 0 0 M2202.08 32.4315 Q2196.08 32.4315 2192.6 37.1306 Q2189.12 41.7891 2189.12 49.9314 Q2189.12 58.0738 2192.56 62.7728 Q2196.04 67.4314 2202.08 67.4314 Q2208.03 67.4314 2211.52 62.7323 Q2215 58.0333 2215 49.9314 Q2215 41.8701 2211.52 37.1711 Q2208.03 32.4315 2202.08 32.4315 M2202.08 26.1121 Q2211.8 26.1121 2217.35 32.4315 Q2222.9 38.7509 2222.9 49.9314 Q2222.9 61.0714 2217.35 67.4314 Q2211.8 73.7508 2202.08 73.7508 Q2192.32 73.7508 2186.77 67.4314 Q2181.26 61.0714 2181.26 49.9314 Q2181.26 38.7509 2186.77 32.4315 Q2192.32 26.1121 2202.08 26.1121 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip100)\" d=\"M 0 0 M2230.44 9.54393 L2237.93 9.54393 L2237.93 46.7717 L2260.17 27.2059 L2269.69 27.2059 L2245.63 48.4326 L2270.7 72.576 L2260.98 72.576 L2237.93 50.4176 L2237.93 72.576 L2230.44 72.576 L2230.44 9.54393 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><polyline clip-path=\"url(#clip102)\" style=\"stroke:#009af9; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  272.201,1002.3 496.641,721.621 721.08,514.803 945.52,293.211 1169.96,160.256 1394.4,160.256 1618.84,204.575 1843.28,307.984 2067.72,307.984 2292.16,1386.4 \n",
       "  \n",
       "  \"/>\n",
       "<circle clip-path=\"url(#clip102)\" cx=\"272.201\" cy=\"1002.3\" r=\"14\" fill=\"#009af9\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n",
       "<circle clip-path=\"url(#clip102)\" cx=\"496.641\" cy=\"721.621\" r=\"14\" fill=\"#009af9\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n",
       "<circle clip-path=\"url(#clip102)\" cx=\"721.08\" cy=\"514.803\" r=\"14\" fill=\"#009af9\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n",
       "<circle clip-path=\"url(#clip102)\" cx=\"945.52\" cy=\"293.211\" r=\"14\" fill=\"#009af9\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n",
       "<circle clip-path=\"url(#clip102)\" cx=\"1169.96\" cy=\"160.256\" r=\"14\" fill=\"#009af9\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n",
       "<circle clip-path=\"url(#clip102)\" cx=\"1394.4\" cy=\"160.256\" r=\"14\" fill=\"#009af9\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n",
       "<circle clip-path=\"url(#clip102)\" cx=\"1618.84\" cy=\"204.575\" r=\"14\" fill=\"#009af9\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n",
       "<circle clip-path=\"url(#clip102)\" cx=\"1843.28\" cy=\"307.984\" r=\"14\" fill=\"#009af9\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n",
       "<circle clip-path=\"url(#clip102)\" cx=\"2067.72\" cy=\"307.984\" r=\"14\" fill=\"#009af9\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n",
       "<circle clip-path=\"url(#clip102)\" cx=\"2292.16\" cy=\"1386.4\" r=\"14\" fill=\"#009af9\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n",
       "<polyline clip-path=\"url(#clip102)\" style=\"stroke:#e26f46; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  -1929.55,662.53 4493.91,662.53 \n",
       "  \"/>\n",
       "<path clip-path=\"url(#clip100)\" d=\"\n",
       "M1806.6 348.236 L2281.38 348.236 L2281.38 166.796 L1806.6 166.796  Z\n",
       "  \" fill=\"#ffffff\" fill-rule=\"evenodd\" fill-opacity=\"1\"/>\n",
       "<polyline clip-path=\"url(#clip100)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  1806.6,348.236 2281.38,348.236 2281.38,166.796 1806.6,166.796 1806.6,348.236 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip100)\" style=\"stroke:#009af9; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  1830.4,227.276 1973.14,227.276 \n",
       "  \"/>\n",
       "<circle clip-path=\"url(#clip100)\" cx=\"1901.77\" cy=\"227.276\" r=\"23\" fill=\"#009af9\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"5.12\"/>\n",
       "<path clip-path=\"url(#clip100)\" d=\"M 0 0 M2012.76 214.602 L2006.42 231.801 L2019.13 231.801 L2012.76 214.602 M2010.12 209.996 L2015.42 209.996 L2028.6 244.556 L2023.73 244.556 L2020.59 235.69 L2005.01 235.69 L2001.86 244.556 L1996.93 244.556 L2010.12 209.996 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip100)\" d=\"M 0 0 M2054.61 228.908 L2054.61 244.556 L2050.35 244.556 L2050.35 229.047 Q2050.35 225.366 2048.92 223.537 Q2047.48 221.709 2044.61 221.709 Q2041.17 221.709 2039.17 223.908 Q2037.18 226.107 2037.18 229.903 L2037.18 244.556 L2032.9 244.556 L2032.9 218.63 L2037.18 218.63 L2037.18 222.658 Q2038.71 220.32 2040.77 219.162 Q2042.85 218.005 2045.56 218.005 Q2050.03 218.005 2052.32 220.783 Q2054.61 223.537 2054.61 228.908 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip100)\" d=\"M 0 0 M2059.08 218.63 L2063.34 218.63 L2063.34 244.556 L2059.08 244.556 L2059.08 218.63 M2059.08 208.537 L2063.34 208.537 L2063.34 213.931 L2059.08 213.931 L2059.08 208.537 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip100)\" d=\"M 0 0 M2084.34 219.394 L2084.34 223.422 Q2082.53 222.496 2080.59 222.033 Q2078.64 221.57 2076.56 221.57 Q2073.39 221.57 2071.79 222.542 Q2070.22 223.514 2070.22 225.459 Q2070.22 226.94 2071.35 227.797 Q2072.48 228.63 2075.91 229.394 L2077.37 229.718 Q2081.91 230.69 2083.8 232.472 Q2085.73 234.232 2085.73 237.403 Q2085.73 241.014 2082.85 243.121 Q2080.01 245.227 2075.01 245.227 Q2072.92 245.227 2070.66 244.81 Q2068.41 244.417 2065.91 243.607 L2065.91 239.209 Q2068.27 240.435 2070.56 241.06 Q2072.85 241.662 2075.1 241.662 Q2078.11 241.662 2079.73 240.644 Q2081.35 239.602 2081.35 237.727 Q2081.35 235.991 2080.17 235.065 Q2079.01 234.139 2075.05 233.283 L2073.57 232.935 Q2069.61 232.102 2067.85 230.389 Q2066.1 228.653 2066.1 225.644 Q2066.1 221.986 2068.69 219.996 Q2071.28 218.005 2076.05 218.005 Q2078.41 218.005 2080.49 218.352 Q2082.58 218.699 2084.34 219.394 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip100)\" d=\"M 0 0 M2100.24 221.616 Q2096.81 221.616 2094.82 224.301 Q2092.83 226.963 2092.83 231.616 Q2092.83 236.269 2094.8 238.954 Q2096.79 241.616 2100.24 241.616 Q2103.64 241.616 2105.63 238.931 Q2107.62 236.246 2107.62 231.616 Q2107.62 227.01 2105.63 224.324 Q2103.64 221.616 2100.24 221.616 M2100.24 218.005 Q2105.79 218.005 2108.97 221.616 Q2112.14 225.227 2112.14 231.616 Q2112.14 237.982 2108.97 241.616 Q2105.79 245.227 2100.24 245.227 Q2094.66 245.227 2091.49 241.616 Q2088.34 237.982 2088.34 231.616 Q2088.34 225.227 2091.49 221.616 Q2094.66 218.005 2100.24 218.005 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip100)\" d=\"M 0 0 M2120.82 211.269 L2120.82 218.63 L2129.59 218.63 L2129.59 221.94 L2120.82 221.94 L2120.82 236.014 Q2120.82 239.185 2121.67 240.088 Q2122.55 240.991 2125.22 240.991 L2129.59 240.991 L2129.59 244.556 L2125.22 244.556 Q2120.29 244.556 2118.41 242.727 Q2116.54 240.875 2116.54 236.014 L2116.54 221.94 L2113.41 221.94 L2113.41 218.63 L2116.54 218.63 L2116.54 211.269 L2120.82 211.269 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip100)\" d=\"M 0 0 M2149.08 222.611 Q2148.36 222.195 2147.51 222.01 Q2146.67 221.801 2145.66 221.801 Q2142.04 221.801 2140.1 224.162 Q2138.18 226.5 2138.18 230.898 L2138.18 244.556 L2133.9 244.556 L2133.9 218.63 L2138.18 218.63 L2138.18 222.658 Q2139.52 220.297 2141.67 219.162 Q2143.83 218.005 2146.91 218.005 Q2147.35 218.005 2147.88 218.074 Q2148.41 218.121 2149.06 218.236 L2149.08 222.611 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip100)\" d=\"M 0 0 M2162.55 221.616 Q2159.13 221.616 2157.14 224.301 Q2155.15 226.963 2155.15 231.616 Q2155.15 236.269 2157.11 238.954 Q2159.1 241.616 2162.55 241.616 Q2165.96 241.616 2167.95 238.931 Q2169.94 236.246 2169.94 231.616 Q2169.94 227.01 2167.95 224.324 Q2165.96 221.616 2162.55 221.616 M2162.55 218.005 Q2168.11 218.005 2171.28 221.616 Q2174.45 225.227 2174.45 231.616 Q2174.45 237.982 2171.28 241.616 Q2168.11 245.227 2162.55 245.227 Q2156.97 245.227 2153.8 241.616 Q2150.66 237.982 2150.66 231.616 Q2150.66 225.227 2153.8 221.616 Q2156.97 218.005 2162.55 218.005 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip100)\" d=\"M 0 0 M2183.04 240.667 L2183.04 254.417 L2178.76 254.417 L2178.76 218.63 L2183.04 218.63 L2183.04 222.565 Q2184.38 220.25 2186.42 219.139 Q2188.48 218.005 2191.33 218.005 Q2196.05 218.005 2198.99 221.755 Q2201.95 225.505 2201.95 231.616 Q2201.95 237.727 2198.99 241.477 Q2196.05 245.227 2191.33 245.227 Q2188.48 245.227 2186.42 244.116 Q2184.38 242.982 2183.04 240.667 M2197.53 231.616 Q2197.53 226.917 2195.59 224.255 Q2193.66 221.57 2190.28 221.57 Q2186.91 221.57 2184.96 224.255 Q2183.04 226.917 2183.04 231.616 Q2183.04 236.315 2184.96 239 Q2186.91 241.662 2190.28 241.662 Q2193.66 241.662 2195.59 239 Q2197.53 236.315 2197.53 231.616 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip100)\" d=\"M 0 0 M2206.42 218.63 L2210.68 218.63 L2210.68 244.556 L2206.42 244.556 L2206.42 218.63 M2206.42 208.537 L2210.68 208.537 L2210.68 213.931 L2206.42 213.931 L2206.42 208.537 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip100)\" d=\"M 0 0 M2233.8 219.625 L2233.8 223.607 Q2232 222.611 2230.17 222.125 Q2228.36 221.616 2226.51 221.616 Q2222.37 221.616 2220.08 224.255 Q2217.78 226.871 2217.78 231.616 Q2217.78 236.361 2220.08 239 Q2222.37 241.616 2226.51 241.616 Q2228.36 241.616 2230.17 241.13 Q2232 240.621 2233.8 239.625 L2233.8 243.56 Q2232.02 244.394 2230.1 244.81 Q2228.2 245.227 2226.05 245.227 Q2220.19 245.227 2216.74 241.546 Q2213.29 237.866 2213.29 231.616 Q2213.29 225.273 2216.77 221.639 Q2220.26 218.005 2226.33 218.005 Q2228.29 218.005 2230.17 218.422 Q2232.04 218.815 2233.8 219.625 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><polyline clip-path=\"url(#clip100)\" style=\"stroke:#e26f46; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  1830.4,287.756 1973.14,287.756 \n",
       "  \"/>\n",
       "<path clip-path=\"url(#clip100)\" d=\"M 0 0 M1996.93 270.476 L2001.61 270.476 L2001.61 301.101 L2018.43 301.101 L2018.43 305.036 L1996.93 305.036 L1996.93 270.476 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip100)\" d=\"M 0 0 M2027.53 301.101 L2043.85 301.101 L2043.85 305.036 L2021.91 305.036 L2021.91 301.101 Q2024.57 298.346 2029.15 293.716 Q2033.76 289.064 2034.94 287.721 Q2037.18 285.198 2038.06 283.462 Q2038.97 281.703 2038.97 280.013 Q2038.97 277.258 2037.02 275.522 Q2035.1 273.786 2032 273.786 Q2029.8 273.786 2027.35 274.55 Q2024.92 275.314 2022.14 276.865 L2022.14 272.142 Q2024.96 271.008 2027.42 270.429 Q2029.87 269.851 2031.91 269.851 Q2037.28 269.851 2040.47 272.536 Q2043.67 275.221 2043.67 279.712 Q2043.67 281.841 2042.85 283.763 Q2042.07 285.661 2039.96 288.253 Q2039.38 288.925 2036.28 292.142 Q2033.18 295.337 2027.53 301.101 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip100)\" d=\"M 0 0 M2063.57 270.476 L2068.25 270.476 L2068.25 301.101 L2085.08 301.101 L2085.08 305.036 L2063.57 305.036 L2063.57 270.476 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip100)\" d=\"M 0 0 M2098.76 282.096 Q2095.33 282.096 2093.34 284.781 Q2091.35 287.443 2091.35 292.096 Q2091.35 296.749 2093.32 299.434 Q2095.31 302.096 2098.76 302.096 Q2102.16 302.096 2104.15 299.411 Q2106.14 296.726 2106.14 292.096 Q2106.14 287.49 2104.15 284.804 Q2102.16 282.096 2098.76 282.096 M2098.76 278.485 Q2104.31 278.485 2107.48 282.096 Q2110.66 285.707 2110.66 292.096 Q2110.66 298.462 2107.48 302.096 Q2104.31 305.707 2098.76 305.707 Q2093.18 305.707 2090.01 302.096 Q2086.86 298.462 2086.86 292.096 Q2086.86 285.707 2090.01 282.096 Q2093.18 278.485 2098.76 278.485 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip100)\" d=\"M 0 0 M2131.65 279.874 L2131.65 283.902 Q2129.85 282.976 2127.9 282.513 Q2125.96 282.05 2123.87 282.05 Q2120.7 282.05 2119.1 283.022 Q2117.53 283.994 2117.53 285.939 Q2117.53 287.42 2118.66 288.277 Q2119.8 289.11 2123.22 289.874 L2124.68 290.198 Q2129.22 291.17 2131.12 292.952 Q2133.04 294.712 2133.04 297.883 Q2133.04 301.494 2130.17 303.601 Q2127.32 305.707 2122.32 305.707 Q2120.24 305.707 2117.97 305.29 Q2115.72 304.897 2113.22 304.087 L2113.22 299.689 Q2115.59 300.915 2117.88 301.54 Q2120.17 302.142 2122.41 302.142 Q2125.42 302.142 2127.04 301.124 Q2128.66 300.082 2128.66 298.207 Q2128.66 296.471 2127.48 295.545 Q2126.33 294.619 2122.37 293.763 L2120.89 293.415 Q2116.93 292.582 2115.17 290.869 Q2113.41 289.133 2113.41 286.124 Q2113.41 282.466 2116 280.476 Q2118.6 278.485 2123.36 278.485 Q2125.72 278.485 2127.81 278.832 Q2129.89 279.179 2131.65 279.874 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip100)\" d=\"M 0 0 M2154.03 279.874 L2154.03 283.902 Q2152.23 282.976 2150.28 282.513 Q2148.34 282.05 2146.26 282.05 Q2143.09 282.05 2141.49 283.022 Q2139.91 283.994 2139.91 285.939 Q2139.91 287.42 2141.05 288.277 Q2142.18 289.11 2145.61 289.874 L2147.07 290.198 Q2151.6 291.17 2153.5 292.952 Q2155.42 294.712 2155.42 297.883 Q2155.42 301.494 2152.55 303.601 Q2149.71 305.707 2144.71 305.707 Q2142.62 305.707 2140.35 305.29 Q2138.11 304.897 2135.61 304.087 L2135.61 299.689 Q2137.97 300.915 2140.26 301.54 Q2142.55 302.142 2144.8 302.142 Q2147.81 302.142 2149.43 301.124 Q2151.05 300.082 2151.05 298.207 Q2151.05 296.471 2149.87 295.545 Q2148.71 294.619 2144.75 293.763 L2143.27 293.415 Q2139.31 292.582 2137.55 290.869 Q2135.79 289.133 2135.79 286.124 Q2135.79 282.466 2138.39 280.476 Q2140.98 278.485 2145.75 278.485 Q2148.11 278.485 2150.19 278.832 Q2152.28 279.179 2154.03 279.874 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /></svg>\n"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plot(Ts[2:end], scores[2:end], label=\"Anisotropic\", marker=:dot)\n",
    "hline!([scores[1]], label=\"L2 Loss\")\n",
    "plot!(title=\"Recall 1@$(recalln) on 1000x16 artifical data, $(n_codebooks)x$(n_centers) codebook\", \n",
    "      xlabel=\"T\",\n",
    "      ylabel=\"Recall 1@$(recalln)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparison to L2 loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-02-08T16:37:26.092Z"
    }
   },
   "outputs": [],
   "source": [
    "function get1atNscores(ranking, n_neighbors, groundtruth)\n",
    "    scores = zeros(n_neighbors)\n",
    "    for i in 1:n_neighbors\n",
    "        scores[i] = recall1atN(ranking, groundtruth, i)\n",
    "    end\n",
    "    return scores\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training Tuned Anisotropic PQ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-02-08T16:37:26.508Z"
    }
   },
   "outputs": [],
   "source": [
    "traindata = deepcopy(data)\n",
    "ahpq = builder(traindata, T=Ts[argmax(scores)], n_codebooks=n_codebooks, \n",
    "                                    n_centers=n_centers,\n",
    "                                    verbose=true,\n",
    "                                    stopcond=stopcond,\n",
    "                                    a=0,\n",
    "                                    training_points=-1);\n",
    "yhat = AHPQ.MIPS(ahpq, queries, n_neighbors)\n",
    "anisotropic_scores  = get1atNscores(yhat, n_neighbors, groundtruth);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training L2 PQ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-02-08T16:37:27.605Z"
    }
   },
   "outputs": [],
   "source": [
    "traindata = deepcopy(data)\n",
    "ahpq = builder(traindata, T=0, n_codebooks=n_codebooks, \n",
    "                                    n_centers=n_centers,\n",
    "                                    verbose=true,\n",
    "                                    stopcond=stopcond,\n",
    "                                    a=0,\n",
    "                                    training_points=-1);\n",
    "yhat = AHPQ.MIPS(ahpq, queries, n_neighbors)\n",
    "L2_scores  = get1atNscores(yhat, n_neighbors, groundtruth);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-02-08T16:37:27.861Z"
    }
   },
   "outputs": [],
   "source": [
    "plot(1:100, anisotropic_scores, label=\"Anisotropic\")\n",
    "plot!(1:100, L2_scores, label=\"L2\")\n",
    "plot!(title=\"Recall on 1000x16 artifical data, $(n_codebooks)x$(n_centers) codebook\", \n",
    "      xlabel=\"N\",\n",
    "      ylabel=\"Recall 1@N\",\n",
    "      legend=:bottomright)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 100x1.000 Dataset: Varying `n_codebooks`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-05T16:28:45.537000+01:00",
     "start_time": "2021-02-05T15:25:49.138Z"
    }
   },
   "outputs": [],
   "source": [
    "## Artificial Data Generation ##\n",
    "n_dp = 1000\n",
    "n_dim = 100\n",
    "n_queries = 2000\n",
    "n_neighbors = 100\n",
    "\n",
    "data = rand(n_dim, n_dp)\n",
    "data = data ./ mapslices(norm, data, dims=1)\n",
    "queries = rand(n_dim, n_queries)\n",
    "innerproducts = data' * queries\n",
    "groundtruth = mapslices(x -> partialsortperm(x, 1:n_neighbors, rev=true), innerproducts,dims=1);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-05T16:28:45.539000+01:00",
     "start_time": "2021-02-05T15:25:49.139Z"
    }
   },
   "outputs": [],
   "source": [
    "n_centers = 16\n",
    "n_codebooks = [2, 5, 10, 25, 50, 100]\n",
    "nrecall = 20\n",
    "stopcond=1e-2;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tuning `T`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-05T16:32:28.464000+01:00",
     "start_time": "2021-02-05T15:25:49.146Z"
    }
   },
   "outputs": [],
   "source": [
    "Ts = 0.001:0.1:1\n",
    "scores = zeros(length(Ts))\n",
    "for i in 1:length(Ts)\n",
    "    traindata=deepcopy(data)\n",
    "    ahpq = builder(traindata; T=Ts[i], n_codebooks=5, \n",
    "                                    n_centers=n_centers,\n",
    "                                    verbose=false,\n",
    "                                    stopcond=stopcond,\n",
    "                                    a=0,\n",
    "                                    training_points=-1,\n",
    "                                    optimisation=\"nesterov\")\n",
    "    yhat = MIPS(ahpq, queries, n_neighbors)\n",
    "    scores[i] = recall1atN(yhat, groundtruth, recalln)\n",
    "end\n",
    "print(\"Optimal T found at $(Ts[argmax(scores)])\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-05T16:32:28.492000+01:00",
     "start_time": "2021-02-05T15:25:49.148Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plot(Ts, scores[1:10], marker=:dot)\n",
    "plot!(title=\"Recall 1@$(nrecall) on 1000x16 artifical data, 5x$(n_centers) codebook\", \n",
    "      xlabel=\"T\",\n",
    "      ylabel=\"Recall 1@$(nrecall)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performing tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-05T16:32:42.218000+01:00",
     "start_time": "2021-02-05T15:25:49.153Z"
    }
   },
   "outputs": [],
   "source": [
    "euclidean_errors = zeros(length(n_codebooks))\n",
    "euclidean_scores = zeros(length(n_codebooks))\n",
    "for i in 1:length(n_codebooks)\n",
    "    traindata=deepcopy(data)\n",
    "    ahpq = builder(traindata; T=0, n_codebooks=n_codebooks[i], \n",
    "                                    n_centers=n_centers,\n",
    "                                    verbose=false,\n",
    "                                    stopcond=stopcond,\n",
    "                                    a=0,\n",
    "                                    training_points=-1)\n",
    "    euclidean_errors[i] = approx_error(ahpq.qd, data, groundtruth, queries)\n",
    "    yhat = MIPS(ahpq, queries, n_neighbors)\n",
    "    euclidean_scores[i] = recallN(yhat, groundtruth, nrecall)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-05T16:37:12.627000+01:00",
     "start_time": "2021-02-05T15:25:49.157Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "anisotropic_errors = zeros(length(n_codebooks))\n",
    "anisotropic_scores = zeros(length(n_codebooks))\n",
    "for i in 1:length(n_codebooks)\n",
    "    traindata=deepcopy(data)\n",
    "    ahpq = builder(traindata; T=Ts[argmax(scores)], n_codebooks=n_codebooks[i], \n",
    "                                    n_centers=n_centers,\n",
    "                                    verbose=false,\n",
    "                                    stopcond=stopcond,\n",
    "                                    a=0,\n",
    "                                    training_points=-1)\n",
    "    anisotropic_errors[i] = approx_error(ahpq.qd, data, groundtruth, queries)\n",
    "    yhat = MIPS(ahpq, queries, n_neighbors)\n",
    "    anisotropic_scores[i] = recallN(yhat, groundtruth, nrecall)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-05T16:37:13.032000+01:00",
     "start_time": "2021-02-05T15:25:49.159Z"
    }
   },
   "outputs": [],
   "source": [
    "plot(n_codebooks, anisotropic_errors, marker=:dot, label=\"Anisotropic\")\n",
    "plot!(n_codebooks, euclidean_errors, marker=:dot, label=\"Reconstruction\")\n",
    "plot!(title=\"Relative Error on Top-1 of Artificial Dataset\", \n",
    "      xlabel=\"N Codebooks\",\n",
    "      ylabel=\"| < q, x-̃x > - < q, x > |\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-05T16:37:13.055000+01:00",
     "start_time": "2021-02-05T15:25:49.162Z"
    }
   },
   "outputs": [],
   "source": [
    "plot(n_codebooks, anisotropic_scores, marker=:dot, label=\"Anisotropic\")\n",
    "plot!(n_codebooks, euclidean_scores, marker=:dot, label=\"Reconstruction\")\n",
    "plot!(title=\"Recall10 on 1000x100 artifical data\", \n",
    "      xlabel=\"N Codebooks\",\n",
    "      ylabel=\"Recall 10@10\",\n",
    "      legend=:bottomright)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 4 Threads 1.5.2",
   "language": "julia",
   "name": "julia-4-threads-1.5"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.5.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
